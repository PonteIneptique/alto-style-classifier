{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         _ : 0.91 of the whole (38663)\n",
      "   italics : 0.04 of the whole (1731)\n",
      "      bold : 0.05 of the whole (1928)\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from collections import namedtuple, defaultdict\n",
    "import lxml.etree as et\n",
    "import os\n",
    "\n",
    "class NoSourceImage(Exception):\n",
    "    \"\"\" Raised when the ALTO is missing a link to an image file \"\"\"\n",
    "\n",
    "BBOX = namedtuple(\"Bbox\", [\"x1\", \"y1\", \"x2\", \"y2\", \"file\", \"id\", \"image\"])\n",
    "NS = {\"a\": \"http://www.loc.gov/standards/alto/ns-v2#\"}\n",
    "\n",
    "def temporary_replace_path(xml_path):\n",
    "    return f\"../IMG/{xml_path.replace('.xml', '.jpg')}\"\n",
    "\n",
    "def read_alto(alto_xml) -> Tuple[Dict[str, List[BBOX]], str]:\n",
    "    classes = defaultdict(list)\n",
    "    \n",
    "    with open(alto_xml) as f:\n",
    "        xml = et.parse(f)\n",
    "        source_image = xml.xpath(\"//a:sourceImageInformation/a:fileName/text()\", namespaces=NS)\n",
    "        if not len(source_image):\n",
    "            raise NoSourceImage(f\"{alto_xml} is missing the following node\"\n",
    "                                \"`/alto/Description/sourceImageInformation/fileName`\"\n",
    "                               \"which should contain the path to the image it is about\")\n",
    "        source_image = temporary_replace_path(source_image[0])\n",
    "        real_path = os.path.abspath(\n",
    "            os.path.join(os.path.dirname(alto_xml), source_image)\n",
    "        )\n",
    "        if not os.path.isfile(real_path):\n",
    "            raise NoSourceImage(f\"{alto_xml} has a wrong path at\"\n",
    "                                \"`/alto/Description/sourceImageInformation/fileName`\"\n",
    "                               f\": {real_path}\")\n",
    "        \n",
    "        styles = {\n",
    "            style.attrib[\"ID\"]: style.attrib[\"FONTSTYLE\"] if style.attrib[\"FONTSTYLE\"] else \"_\"\n",
    "            for style in xml.xpath(\"//a:TextStyle\", namespaces=NS)\n",
    "        }\n",
    "        for string in xml.xpath(\"//a:String\", namespaces=NS):\n",
    "            x, y, = string.attrib[\"HPOS\"], string.attrib[\"VPOS\"]\n",
    "            w, h = string.attrib[\"WIDTH\"], string.attrib[\"HEIGHT\"]\n",
    "            x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "            style = styles[string.attrib[\"STYLEREFS\"]]\n",
    "            classes[style].append(BBOX(x, y, x+w, y+h, alto_xml, \n",
    "                                       string.attrib[\"ID\"], real_path))\n",
    "            \n",
    "    return classes, real_path\n",
    "\n",
    "import glob\n",
    "\n",
    "data = defaultdict(list)\n",
    "for xml_path in glob.glob(\"./input/*/ALTO/*.xml\"):\n",
    "    current, image = read_alto(xml_path)\n",
    "    for key in current:\n",
    "        data[key].extend(current[key])\n",
    "    \n",
    "minimum = float(\"inf\")\n",
    "for cls in data:\n",
    "    total = sum([len(val) for val in data.values()])\n",
    "    print(f\"{cls.zfill(10).replace('0', ' ')} : {len(data[cls])/total:.2f} of the whole ({len(data[cls])})\")\n",
    "    minimum = min([len(data[cls]), minimum])\n",
    "print(minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "import PIL.Image as PILImage\n",
    "#import tqdm.tqdm\n",
    "\n",
    "output_dir = \"./data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "source = PILImage.open(image)\n",
    "for cls, items in data.items():\n",
    "    os.makedirs(os.path.join(output_dir, cls), exist_ok=True)\n",
    "    for id_, bbox in enumerate(items):\n",
    "        area = source.crop(bbox[:4])\n",
    "        area.save(\n",
    "            os.path.join(\n",
    "                output_dir,\n",
    "                cls,\n",
    "                f\"{os.path.basename(bbox.image)}.{id_}.png\"\n",
    "            )\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and generate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_dir = \"./test_data\"\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for cls in glob.glob(\"./data/*\"):\n",
    "    files = glob.glob(os.path.join(cls, \"*.png\"))\n",
    "    random.shuffle(files)\n",
    "    os.makedirs(cls.replace(\"data\", \"test_data\"), exist_ok=True)\n",
    "    for file in files[:int(minimum*0.1)]:\n",
    "        os.rename(file, file.replace(\"data\", \"test_data\"))\n",
    "        \n",
    "train_dir = \"./train_data\"\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "for cls in glob.glob(\"./data/*\"):\n",
    "    files = glob.glob(os.path.join(cls, \"*.png\"))\n",
    "    random.shuffle(files)\n",
    "    os.makedirs(cls.replace(\"data\", train_dir), exist_ok=True)\n",
    "    for file in files[:minimum]:\n",
    "        os.rename(file, file.replace(\"data\", train_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "\n",
    "pre_process = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transform=pre_process\n",
    ")\n",
    "testset = torchvision.datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transform=pre_process\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4,\n",
    "    shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4,\n",
    "    shuffle=True, num_workers=2\n",
    ")\n",
    "classes = {n: key for n, key in enumerate(dataset.classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes bold italics  bold  bold\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\"Classes\" + ' '.join('%5s' % classes[labels[j].tolist()] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count classes in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'bold': 173, 'italics': 173, '_': 173})\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "from collections import Counter\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "\n",
    "out = []\n",
    "for images, labels in dataiter:\n",
    "    out.extend([classes[labels[j].tolist()] for j in range(len(labels))])\n",
    "    \n",
    "print(Counter(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "network = Net(len(classes))\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(trainloader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(trainloader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "        100. * batch_idx / len(trainloader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(trainloader.dataset)))\n",
    "      torch.save(network.state_dict(), './results/model.pth')\n",
    "      torch.save(optimizer.state_dict(), './results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(testloader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(testloader.dataset),\n",
    "    100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/alto-fontstyle-classifier/env/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/thibault/dev/alto-fontstyle-classifier/env/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.0991, Accuracy: 174/519 (34%)\n",
      "\n",
      "Train Epoch: 1 [0/5020 (0%)]\tLoss: 1.130505\n",
      "Train Epoch: 1 [40/5020 (1%)]\tLoss: 1.167869\n",
      "Train Epoch: 1 [80/5020 (2%)]\tLoss: 1.111868\n",
      "Train Epoch: 1 [120/5020 (2%)]\tLoss: 1.105965\n",
      "Train Epoch: 1 [160/5020 (3%)]\tLoss: 1.142885\n",
      "Train Epoch: 1 [200/5020 (4%)]\tLoss: 1.134617\n",
      "Train Epoch: 1 [240/5020 (5%)]\tLoss: 1.038367\n",
      "Train Epoch: 1 [280/5020 (6%)]\tLoss: 1.086922\n",
      "Train Epoch: 1 [320/5020 (6%)]\tLoss: 1.058128\n",
      "Train Epoch: 1 [360/5020 (7%)]\tLoss: 1.102284\n",
      "Train Epoch: 1 [400/5020 (8%)]\tLoss: 1.104639\n",
      "Train Epoch: 1 [440/5020 (9%)]\tLoss: 1.108813\n",
      "Train Epoch: 1 [480/5020 (10%)]\tLoss: 1.133524\n",
      "Train Epoch: 1 [520/5020 (10%)]\tLoss: 1.020472\n",
      "Train Epoch: 1 [560/5020 (11%)]\tLoss: 1.113517\n",
      "Train Epoch: 1 [600/5020 (12%)]\tLoss: 1.094149\n",
      "Train Epoch: 1 [640/5020 (13%)]\tLoss: 1.118983\n",
      "Train Epoch: 1 [680/5020 (14%)]\tLoss: 1.080164\n",
      "Train Epoch: 1 [720/5020 (14%)]\tLoss: 1.113295\n",
      "Train Epoch: 1 [760/5020 (15%)]\tLoss: 1.090271\n",
      "Train Epoch: 1 [800/5020 (16%)]\tLoss: 1.085091\n",
      "Train Epoch: 1 [840/5020 (17%)]\tLoss: 1.059430\n",
      "Train Epoch: 1 [880/5020 (18%)]\tLoss: 1.091562\n",
      "Train Epoch: 1 [920/5020 (18%)]\tLoss: 1.102473\n",
      "Train Epoch: 1 [960/5020 (19%)]\tLoss: 1.095047\n",
      "Train Epoch: 1 [1000/5020 (20%)]\tLoss: 1.114354\n",
      "Train Epoch: 1 [1040/5020 (21%)]\tLoss: 1.102940\n",
      "Train Epoch: 1 [1080/5020 (22%)]\tLoss: 1.008154\n",
      "Train Epoch: 1 [1120/5020 (22%)]\tLoss: 1.161157\n",
      "Train Epoch: 1 [1160/5020 (23%)]\tLoss: 1.082732\n",
      "Train Epoch: 1 [1200/5020 (24%)]\tLoss: 1.054079\n",
      "Train Epoch: 1 [1240/5020 (25%)]\tLoss: 1.093584\n",
      "Train Epoch: 1 [1280/5020 (25%)]\tLoss: 1.085715\n",
      "Train Epoch: 1 [1320/5020 (26%)]\tLoss: 1.134861\n",
      "Train Epoch: 1 [1360/5020 (27%)]\tLoss: 1.077731\n",
      "Train Epoch: 1 [1400/5020 (28%)]\tLoss: 1.083121\n",
      "Train Epoch: 1 [1440/5020 (29%)]\tLoss: 1.118335\n",
      "Train Epoch: 1 [1480/5020 (29%)]\tLoss: 1.077818\n",
      "Train Epoch: 1 [1520/5020 (30%)]\tLoss: 1.070245\n",
      "Train Epoch: 1 [1560/5020 (31%)]\tLoss: 1.108827\n",
      "Train Epoch: 1 [1600/5020 (32%)]\tLoss: 1.237553\n",
      "Train Epoch: 1 [1640/5020 (33%)]\tLoss: 1.154645\n",
      "Train Epoch: 1 [1680/5020 (33%)]\tLoss: 1.116934\n",
      "Train Epoch: 1 [1720/5020 (34%)]\tLoss: 1.142147\n",
      "Train Epoch: 1 [1760/5020 (35%)]\tLoss: 1.102331\n",
      "Train Epoch: 1 [1800/5020 (36%)]\tLoss: 1.102018\n",
      "Train Epoch: 1 [1840/5020 (37%)]\tLoss: 1.105768\n",
      "Train Epoch: 1 [1880/5020 (37%)]\tLoss: 1.089615\n",
      "Train Epoch: 1 [1920/5020 (38%)]\tLoss: 1.134083\n",
      "Train Epoch: 1 [1960/5020 (39%)]\tLoss: 1.109862\n",
      "Train Epoch: 1 [2000/5020 (40%)]\tLoss: 1.088346\n",
      "Train Epoch: 1 [2040/5020 (41%)]\tLoss: 1.080516\n",
      "Train Epoch: 1 [2080/5020 (41%)]\tLoss: 1.096555\n",
      "Train Epoch: 1 [2120/5020 (42%)]\tLoss: 1.106812\n",
      "Train Epoch: 1 [2160/5020 (43%)]\tLoss: 1.110469\n",
      "Train Epoch: 1 [2200/5020 (44%)]\tLoss: 1.093521\n",
      "Train Epoch: 1 [2240/5020 (45%)]\tLoss: 1.052550\n",
      "Train Epoch: 1 [2280/5020 (45%)]\tLoss: 1.154185\n",
      "Train Epoch: 1 [2320/5020 (46%)]\tLoss: 1.051184\n",
      "Train Epoch: 1 [2360/5020 (47%)]\tLoss: 1.090617\n",
      "Train Epoch: 1 [2400/5020 (48%)]\tLoss: 1.114815\n",
      "Train Epoch: 1 [2440/5020 (49%)]\tLoss: 1.054180\n",
      "Train Epoch: 1 [2480/5020 (49%)]\tLoss: 1.125393\n",
      "Train Epoch: 1 [2520/5020 (50%)]\tLoss: 1.096962\n",
      "Train Epoch: 1 [2560/5020 (51%)]\tLoss: 1.079833\n",
      "Train Epoch: 1 [2600/5020 (52%)]\tLoss: 1.112406\n",
      "Train Epoch: 1 [2640/5020 (53%)]\tLoss: 1.106849\n",
      "Train Epoch: 1 [2680/5020 (53%)]\tLoss: 1.080516\n",
      "Train Epoch: 1 [2720/5020 (54%)]\tLoss: 1.080210\n",
      "Train Epoch: 1 [2760/5020 (55%)]\tLoss: 1.112447\n",
      "Train Epoch: 1 [2800/5020 (56%)]\tLoss: 1.078879\n",
      "Train Epoch: 1 [2840/5020 (57%)]\tLoss: 1.105834\n",
      "Train Epoch: 1 [2880/5020 (57%)]\tLoss: 1.088835\n",
      "Train Epoch: 1 [2920/5020 (58%)]\tLoss: 1.115599\n",
      "Train Epoch: 1 [2960/5020 (59%)]\tLoss: 1.041090\n",
      "Train Epoch: 1 [3000/5020 (60%)]\tLoss: 1.073122\n",
      "Train Epoch: 1 [3040/5020 (61%)]\tLoss: 1.112317\n",
      "Train Epoch: 1 [3080/5020 (61%)]\tLoss: 1.089103\n",
      "Train Epoch: 1 [3120/5020 (62%)]\tLoss: 1.115488\n",
      "Train Epoch: 1 [3160/5020 (63%)]\tLoss: 1.073089\n",
      "Train Epoch: 1 [3200/5020 (64%)]\tLoss: 1.078782\n",
      "Train Epoch: 1 [3240/5020 (65%)]\tLoss: 1.104171\n",
      "Train Epoch: 1 [3280/5020 (65%)]\tLoss: 1.097274\n",
      "Train Epoch: 1 [3320/5020 (66%)]\tLoss: 1.104756\n",
      "Train Epoch: 1 [3360/5020 (67%)]\tLoss: 1.082496\n",
      "Train Epoch: 1 [3400/5020 (68%)]\tLoss: 1.070012\n",
      "Train Epoch: 1 [3440/5020 (69%)]\tLoss: 1.061182\n",
      "Train Epoch: 1 [3480/5020 (69%)]\tLoss: 1.086156\n",
      "Train Epoch: 1 [3520/5020 (70%)]\tLoss: 1.094706\n",
      "Train Epoch: 1 [3560/5020 (71%)]\tLoss: 1.110980\n",
      "Train Epoch: 1 [3600/5020 (72%)]\tLoss: 1.068505\n",
      "Train Epoch: 1 [3640/5020 (73%)]\tLoss: 1.075864\n",
      "Train Epoch: 1 [3680/5020 (73%)]\tLoss: 1.112926\n",
      "Train Epoch: 1 [3720/5020 (74%)]\tLoss: 1.079488\n",
      "Train Epoch: 1 [3760/5020 (75%)]\tLoss: 1.093817\n",
      "Train Epoch: 1 [3800/5020 (76%)]\tLoss: 1.104207\n",
      "Train Epoch: 1 [3840/5020 (76%)]\tLoss: 1.112626\n",
      "Train Epoch: 1 [3880/5020 (77%)]\tLoss: 1.134756\n",
      "Train Epoch: 1 [3920/5020 (78%)]\tLoss: 1.050907\n",
      "Train Epoch: 1 [3960/5020 (79%)]\tLoss: 1.112778\n",
      "Train Epoch: 1 [4000/5020 (80%)]\tLoss: 1.049796\n",
      "Train Epoch: 1 [4040/5020 (80%)]\tLoss: 1.115148\n",
      "Train Epoch: 1 [4080/5020 (81%)]\tLoss: 1.095025\n",
      "Train Epoch: 1 [4120/5020 (82%)]\tLoss: 1.100399\n",
      "Train Epoch: 1 [4160/5020 (83%)]\tLoss: 1.137364\n",
      "Train Epoch: 1 [4200/5020 (84%)]\tLoss: 1.094633\n",
      "Train Epoch: 1 [4240/5020 (84%)]\tLoss: 1.135868\n",
      "Train Epoch: 1 [4280/5020 (85%)]\tLoss: 1.047549\n",
      "Train Epoch: 1 [4320/5020 (86%)]\tLoss: 1.108925\n",
      "Train Epoch: 1 [4360/5020 (87%)]\tLoss: 1.086775\n",
      "Train Epoch: 1 [4400/5020 (88%)]\tLoss: 1.174921\n",
      "Train Epoch: 1 [4440/5020 (88%)]\tLoss: 1.123291\n",
      "Train Epoch: 1 [4480/5020 (89%)]\tLoss: 1.087085\n",
      "Train Epoch: 1 [4520/5020 (90%)]\tLoss: 1.114357\n",
      "Train Epoch: 1 [4560/5020 (91%)]\tLoss: 1.054614\n",
      "Train Epoch: 1 [4600/5020 (92%)]\tLoss: 1.083817\n",
      "Train Epoch: 1 [4640/5020 (92%)]\tLoss: 1.116531\n",
      "Train Epoch: 1 [4680/5020 (93%)]\tLoss: 1.100369\n",
      "Train Epoch: 1 [4720/5020 (94%)]\tLoss: 1.084634\n",
      "Train Epoch: 1 [4760/5020 (95%)]\tLoss: 1.060481\n",
      "Train Epoch: 1 [4800/5020 (96%)]\tLoss: 1.131876\n",
      "Train Epoch: 1 [4840/5020 (96%)]\tLoss: 1.150299\n",
      "Train Epoch: 1 [4880/5020 (97%)]\tLoss: 1.064395\n",
      "Train Epoch: 1 [4920/5020 (98%)]\tLoss: 1.077515\n",
      "Train Epoch: 1 [4960/5020 (99%)]\tLoss: 1.114559\n",
      "Train Epoch: 1 [5000/5020 (100%)]\tLoss: 1.130987\n",
      "\n",
      "Test set: Avg. loss: 1.1001, Accuracy: 168/519 (32%)\n",
      "\n",
      "Train Epoch: 2 [0/5020 (0%)]\tLoss: 1.113728\n",
      "Train Epoch: 2 [40/5020 (1%)]\tLoss: 1.134886\n",
      "Train Epoch: 2 [80/5020 (2%)]\tLoss: 1.005495\n",
      "Train Epoch: 2 [120/5020 (2%)]\tLoss: 1.088515\n",
      "Train Epoch: 2 [160/5020 (3%)]\tLoss: 1.139647\n",
      "Train Epoch: 2 [200/5020 (4%)]\tLoss: 1.057000\n",
      "Train Epoch: 2 [240/5020 (5%)]\tLoss: 1.036612\n",
      "Train Epoch: 2 [280/5020 (6%)]\tLoss: 1.074750\n",
      "Train Epoch: 2 [320/5020 (6%)]\tLoss: 1.127944\n",
      "Train Epoch: 2 [360/5020 (7%)]\tLoss: 1.039447\n",
      "Train Epoch: 2 [400/5020 (8%)]\tLoss: 1.122674\n",
      "Train Epoch: 2 [440/5020 (9%)]\tLoss: 1.090348\n",
      "Train Epoch: 2 [480/5020 (10%)]\tLoss: 1.125006\n",
      "Train Epoch: 2 [520/5020 (10%)]\tLoss: 1.094940\n",
      "Train Epoch: 2 [560/5020 (11%)]\tLoss: 1.062241\n",
      "Train Epoch: 2 [600/5020 (12%)]\tLoss: 1.113058\n",
      "Train Epoch: 2 [640/5020 (13%)]\tLoss: 1.155682\n",
      "Train Epoch: 2 [680/5020 (14%)]\tLoss: 1.045735\n",
      "Train Epoch: 2 [720/5020 (14%)]\tLoss: 1.087931\n",
      "Train Epoch: 2 [760/5020 (15%)]\tLoss: 1.098509\n",
      "Train Epoch: 2 [800/5020 (16%)]\tLoss: 1.107211\n",
      "Train Epoch: 2 [840/5020 (17%)]\tLoss: 1.071450\n",
      "Train Epoch: 2 [880/5020 (18%)]\tLoss: 1.087826\n",
      "Train Epoch: 2 [920/5020 (18%)]\tLoss: 1.082523\n",
      "Train Epoch: 2 [960/5020 (19%)]\tLoss: 1.121808\n",
      "Train Epoch: 2 [1000/5020 (20%)]\tLoss: 1.088961\n",
      "Train Epoch: 2 [1040/5020 (21%)]\tLoss: 1.076496\n",
      "Train Epoch: 2 [1080/5020 (22%)]\tLoss: 1.133630\n",
      "Train Epoch: 2 [1120/5020 (22%)]\tLoss: 1.086191\n",
      "Train Epoch: 2 [1160/5020 (23%)]\tLoss: 1.107255\n",
      "Train Epoch: 2 [1200/5020 (24%)]\tLoss: 1.134629\n",
      "Train Epoch: 2 [1240/5020 (25%)]\tLoss: 1.129465\n",
      "Train Epoch: 2 [1280/5020 (25%)]\tLoss: 1.126917\n",
      "Train Epoch: 2 [1320/5020 (26%)]\tLoss: 1.099526\n",
      "Train Epoch: 2 [1360/5020 (27%)]\tLoss: 1.132333\n",
      "Train Epoch: 2 [1400/5020 (28%)]\tLoss: 1.150184\n",
      "Train Epoch: 2 [1440/5020 (29%)]\tLoss: 1.133339\n",
      "Train Epoch: 2 [1480/5020 (29%)]\tLoss: 1.051011\n",
      "Train Epoch: 2 [1520/5020 (30%)]\tLoss: 1.093949\n",
      "Train Epoch: 2 [1560/5020 (31%)]\tLoss: 1.052253\n",
      "Train Epoch: 2 [1600/5020 (32%)]\tLoss: 0.977349\n",
      "Train Epoch: 2 [1640/5020 (33%)]\tLoss: 1.124588\n",
      "Train Epoch: 2 [1680/5020 (33%)]\tLoss: 1.121994\n",
      "Train Epoch: 2 [1720/5020 (34%)]\tLoss: 0.999010\n",
      "Train Epoch: 2 [1760/5020 (35%)]\tLoss: 1.093249\n",
      "Train Epoch: 2 [1800/5020 (36%)]\tLoss: 1.177225\n",
      "Train Epoch: 2 [1840/5020 (37%)]\tLoss: 1.095824\n",
      "Train Epoch: 2 [1880/5020 (37%)]\tLoss: 1.033452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [1920/5020 (38%)]\tLoss: 1.052822\n",
      "Train Epoch: 2 [1960/5020 (39%)]\tLoss: 1.116410\n",
      "Train Epoch: 2 [2000/5020 (40%)]\tLoss: 1.054382\n",
      "Train Epoch: 2 [2040/5020 (41%)]\tLoss: 1.088969\n",
      "Train Epoch: 2 [2080/5020 (41%)]\tLoss: 1.067372\n",
      "Train Epoch: 2 [2120/5020 (42%)]\tLoss: 1.052779\n",
      "Train Epoch: 2 [2160/5020 (43%)]\tLoss: 1.077110\n",
      "Train Epoch: 2 [2200/5020 (44%)]\tLoss: 1.139269\n",
      "Train Epoch: 2 [2240/5020 (45%)]\tLoss: 1.091914\n",
      "Train Epoch: 2 [2280/5020 (45%)]\tLoss: 1.073414\n",
      "Train Epoch: 2 [2320/5020 (46%)]\tLoss: 1.150339\n",
      "Train Epoch: 2 [2360/5020 (47%)]\tLoss: 1.101429\n",
      "Train Epoch: 2 [2400/5020 (48%)]\tLoss: 1.083692\n",
      "Train Epoch: 2 [2440/5020 (49%)]\tLoss: 1.071304\n",
      "Train Epoch: 2 [2480/5020 (49%)]\tLoss: 1.121988\n",
      "Train Epoch: 2 [2520/5020 (50%)]\tLoss: 1.005033\n",
      "Train Epoch: 2 [2560/5020 (51%)]\tLoss: 1.120510\n",
      "Train Epoch: 2 [2600/5020 (52%)]\tLoss: 0.990209\n",
      "Train Epoch: 2 [2640/5020 (53%)]\tLoss: 1.086406\n",
      "Train Epoch: 2 [2680/5020 (53%)]\tLoss: 1.079069\n",
      "Train Epoch: 2 [2720/5020 (54%)]\tLoss: 1.117363\n",
      "Train Epoch: 2 [2760/5020 (55%)]\tLoss: 1.076622\n",
      "Train Epoch: 2 [2800/5020 (56%)]\tLoss: 1.083888\n",
      "Train Epoch: 2 [2840/5020 (57%)]\tLoss: 1.091575\n",
      "Train Epoch: 2 [2880/5020 (57%)]\tLoss: 1.089549\n",
      "Train Epoch: 2 [2920/5020 (58%)]\tLoss: 1.007708\n",
      "Train Epoch: 2 [2960/5020 (59%)]\tLoss: 1.137299\n",
      "Train Epoch: 2 [3000/5020 (60%)]\tLoss: 1.130662\n",
      "Train Epoch: 2 [3040/5020 (61%)]\tLoss: 1.158805\n",
      "Train Epoch: 2 [3080/5020 (61%)]\tLoss: 1.137357\n",
      "Train Epoch: 2 [3120/5020 (62%)]\tLoss: 1.041160\n",
      "Train Epoch: 2 [3160/5020 (63%)]\tLoss: 0.901895\n",
      "Train Epoch: 2 [3200/5020 (64%)]\tLoss: 1.072115\n",
      "Train Epoch: 2 [3240/5020 (65%)]\tLoss: 1.143064\n",
      "Train Epoch: 2 [3280/5020 (65%)]\tLoss: 1.182799\n",
      "Train Epoch: 2 [3320/5020 (66%)]\tLoss: 1.004673\n",
      "Train Epoch: 2 [3360/5020 (67%)]\tLoss: 1.116983\n",
      "Train Epoch: 2 [3400/5020 (68%)]\tLoss: 0.997224\n",
      "Train Epoch: 2 [3440/5020 (69%)]\tLoss: 1.070631\n",
      "Train Epoch: 2 [3480/5020 (69%)]\tLoss: 1.144949\n",
      "Train Epoch: 2 [3520/5020 (70%)]\tLoss: 1.093258\n",
      "Train Epoch: 2 [3560/5020 (71%)]\tLoss: 1.051152\n",
      "Train Epoch: 2 [3600/5020 (72%)]\tLoss: 1.080818\n",
      "Train Epoch: 2 [3640/5020 (73%)]\tLoss: 1.090857\n",
      "Train Epoch: 2 [3680/5020 (73%)]\tLoss: 1.085883\n",
      "Train Epoch: 2 [3720/5020 (74%)]\tLoss: 1.179231\n",
      "Train Epoch: 2 [3760/5020 (75%)]\tLoss: 1.081931\n",
      "Train Epoch: 2 [3800/5020 (76%)]\tLoss: 1.086080\n",
      "Train Epoch: 2 [3840/5020 (76%)]\tLoss: 1.093842\n",
      "Train Epoch: 2 [3880/5020 (77%)]\tLoss: 1.103395\n",
      "Train Epoch: 2 [3920/5020 (78%)]\tLoss: 1.092405\n",
      "Train Epoch: 2 [3960/5020 (79%)]\tLoss: 1.151960\n",
      "Train Epoch: 2 [4000/5020 (80%)]\tLoss: 1.081161\n",
      "Train Epoch: 2 [4040/5020 (80%)]\tLoss: 1.096319\n",
      "Train Epoch: 2 [4080/5020 (81%)]\tLoss: 1.098661\n",
      "Train Epoch: 2 [4120/5020 (82%)]\tLoss: 0.964414\n",
      "Train Epoch: 2 [4160/5020 (83%)]\tLoss: 1.105412\n",
      "Train Epoch: 2 [4200/5020 (84%)]\tLoss: 1.089096\n",
      "Train Epoch: 2 [4240/5020 (84%)]\tLoss: 1.113342\n",
      "Train Epoch: 2 [4280/5020 (85%)]\tLoss: 1.100701\n",
      "Train Epoch: 2 [4320/5020 (86%)]\tLoss: 1.130396\n",
      "Train Epoch: 2 [4360/5020 (87%)]\tLoss: 1.106243\n",
      "Train Epoch: 2 [4400/5020 (88%)]\tLoss: 1.129241\n",
      "Train Epoch: 2 [4440/5020 (88%)]\tLoss: 1.084458\n",
      "Train Epoch: 2 [4480/5020 (89%)]\tLoss: 1.101239\n",
      "Train Epoch: 2 [4520/5020 (90%)]\tLoss: 1.088664\n",
      "Train Epoch: 2 [4560/5020 (91%)]\tLoss: 1.114355\n",
      "Train Epoch: 2 [4600/5020 (92%)]\tLoss: 1.081411\n",
      "Train Epoch: 2 [4640/5020 (92%)]\tLoss: 1.104603\n",
      "Train Epoch: 2 [4680/5020 (93%)]\tLoss: 1.081877\n",
      "Train Epoch: 2 [4720/5020 (94%)]\tLoss: 1.052580\n",
      "Train Epoch: 2 [4760/5020 (95%)]\tLoss: 1.076709\n",
      "Train Epoch: 2 [4800/5020 (96%)]\tLoss: 1.087401\n",
      "Train Epoch: 2 [4840/5020 (96%)]\tLoss: 1.030720\n",
      "Train Epoch: 2 [4880/5020 (97%)]\tLoss: 1.061159\n",
      "Train Epoch: 2 [4920/5020 (98%)]\tLoss: 0.946041\n",
      "Train Epoch: 2 [4960/5020 (99%)]\tLoss: 1.029219\n",
      "Train Epoch: 2 [5000/5020 (100%)]\tLoss: 1.120133\n",
      "\n",
      "Test set: Avg. loss: 1.0922, Accuracy: 215/519 (41%)\n",
      "\n",
      "Train Epoch: 3 [0/5020 (0%)]\tLoss: 1.147053\n",
      "Train Epoch: 3 [40/5020 (1%)]\tLoss: 1.110990\n",
      "Train Epoch: 3 [80/5020 (2%)]\tLoss: 0.995072\n",
      "Train Epoch: 3 [120/5020 (2%)]\tLoss: 1.066029\n",
      "Train Epoch: 3 [160/5020 (3%)]\tLoss: 1.108916\n",
      "Train Epoch: 3 [200/5020 (4%)]\tLoss: 1.141899\n",
      "Train Epoch: 3 [240/5020 (5%)]\tLoss: 1.078751\n",
      "Train Epoch: 3 [280/5020 (6%)]\tLoss: 1.126081\n",
      "Train Epoch: 3 [320/5020 (6%)]\tLoss: 1.096169\n",
      "Train Epoch: 3 [360/5020 (7%)]\tLoss: 1.080067\n",
      "Train Epoch: 3 [400/5020 (8%)]\tLoss: 1.067383\n",
      "Train Epoch: 3 [440/5020 (9%)]\tLoss: 0.965317\n",
      "Train Epoch: 3 [480/5020 (10%)]\tLoss: 1.045426\n",
      "Train Epoch: 3 [520/5020 (10%)]\tLoss: 1.117477\n",
      "Train Epoch: 3 [560/5020 (11%)]\tLoss: 1.113585\n",
      "Train Epoch: 3 [600/5020 (12%)]\tLoss: 1.109966\n",
      "Train Epoch: 3 [640/5020 (13%)]\tLoss: 1.111966\n",
      "Train Epoch: 3 [680/5020 (14%)]\tLoss: 1.074774\n",
      "Train Epoch: 3 [720/5020 (14%)]\tLoss: 0.962011\n",
      "Train Epoch: 3 [760/5020 (15%)]\tLoss: 1.087209\n",
      "Train Epoch: 3 [800/5020 (16%)]\tLoss: 1.118512\n",
      "Train Epoch: 3 [840/5020 (17%)]\tLoss: 0.993560\n",
      "Train Epoch: 3 [880/5020 (18%)]\tLoss: 1.131747\n",
      "Train Epoch: 3 [920/5020 (18%)]\tLoss: 1.119397\n",
      "Train Epoch: 3 [960/5020 (19%)]\tLoss: 0.993045\n",
      "Train Epoch: 3 [1000/5020 (20%)]\tLoss: 1.128813\n",
      "Train Epoch: 3 [1040/5020 (21%)]\tLoss: 1.067634\n",
      "Train Epoch: 3 [1080/5020 (22%)]\tLoss: 1.081787\n",
      "Train Epoch: 3 [1120/5020 (22%)]\tLoss: 1.018661\n",
      "Train Epoch: 3 [1160/5020 (23%)]\tLoss: 1.109188\n",
      "Train Epoch: 3 [1200/5020 (24%)]\tLoss: 1.133466\n",
      "Train Epoch: 3 [1240/5020 (25%)]\tLoss: 1.009445\n",
      "Train Epoch: 3 [1280/5020 (25%)]\tLoss: 1.093416\n",
      "Train Epoch: 3 [1320/5020 (26%)]\tLoss: 1.162396\n",
      "Train Epoch: 3 [1360/5020 (27%)]\tLoss: 1.022268\n",
      "Train Epoch: 3 [1400/5020 (28%)]\tLoss: 1.129728\n",
      "Train Epoch: 3 [1440/5020 (29%)]\tLoss: 1.122837\n",
      "Train Epoch: 3 [1480/5020 (29%)]\tLoss: 1.132209\n",
      "Train Epoch: 3 [1520/5020 (30%)]\tLoss: 1.103584\n",
      "Train Epoch: 3 [1560/5020 (31%)]\tLoss: 1.110125\n",
      "Train Epoch: 3 [1600/5020 (32%)]\tLoss: 1.116026\n",
      "Train Epoch: 3 [1640/5020 (33%)]\tLoss: 1.142900\n",
      "Train Epoch: 3 [1680/5020 (33%)]\tLoss: 1.117955\n",
      "Train Epoch: 3 [1720/5020 (34%)]\tLoss: 0.853655\n",
      "Train Epoch: 3 [1760/5020 (35%)]\tLoss: 1.150697\n",
      "Train Epoch: 3 [1800/5020 (36%)]\tLoss: 1.013612\n",
      "Train Epoch: 3 [1840/5020 (37%)]\tLoss: 0.983413\n",
      "Train Epoch: 3 [1880/5020 (37%)]\tLoss: 0.701400\n",
      "Train Epoch: 3 [1920/5020 (38%)]\tLoss: 1.185430\n",
      "Train Epoch: 3 [1960/5020 (39%)]\tLoss: 1.004805\n",
      "Train Epoch: 3 [2000/5020 (40%)]\tLoss: 1.132595\n",
      "Train Epoch: 3 [2040/5020 (41%)]\tLoss: 1.287507\n",
      "Train Epoch: 3 [2080/5020 (41%)]\tLoss: 1.090860\n",
      "Train Epoch: 3 [2120/5020 (42%)]\tLoss: 1.081852\n",
      "Train Epoch: 3 [2160/5020 (43%)]\tLoss: 1.009314\n",
      "Train Epoch: 3 [2200/5020 (44%)]\tLoss: 1.074128\n",
      "Train Epoch: 3 [2240/5020 (45%)]\tLoss: 1.066334\n",
      "Train Epoch: 3 [2280/5020 (45%)]\tLoss: 1.139068\n",
      "Train Epoch: 3 [2320/5020 (46%)]\tLoss: 0.989771\n",
      "Train Epoch: 3 [2360/5020 (47%)]\tLoss: 1.076813\n",
      "Train Epoch: 3 [2400/5020 (48%)]\tLoss: 1.068292\n",
      "Train Epoch: 3 [2440/5020 (49%)]\tLoss: 1.165361\n",
      "Train Epoch: 3 [2480/5020 (49%)]\tLoss: 0.999946\n",
      "Train Epoch: 3 [2520/5020 (50%)]\tLoss: 1.119195\n",
      "Train Epoch: 3 [2560/5020 (51%)]\tLoss: 1.298511\n",
      "Train Epoch: 3 [2600/5020 (52%)]\tLoss: 1.121756\n",
      "Train Epoch: 3 [2640/5020 (53%)]\tLoss: 1.127824\n",
      "Train Epoch: 3 [2680/5020 (53%)]\tLoss: 1.055296\n",
      "Train Epoch: 3 [2720/5020 (54%)]\tLoss: 0.887320\n",
      "Train Epoch: 3 [2760/5020 (55%)]\tLoss: 1.084404\n",
      "Train Epoch: 3 [2800/5020 (56%)]\tLoss: 1.114307\n",
      "Train Epoch: 3 [2840/5020 (57%)]\tLoss: 1.027570\n",
      "Train Epoch: 3 [2880/5020 (57%)]\tLoss: 1.187860\n",
      "Train Epoch: 3 [2920/5020 (58%)]\tLoss: 1.036938\n",
      "Train Epoch: 3 [2960/5020 (59%)]\tLoss: 1.048663\n",
      "Train Epoch: 3 [3000/5020 (60%)]\tLoss: 1.072484\n",
      "Train Epoch: 3 [3040/5020 (61%)]\tLoss: 1.100005\n",
      "Train Epoch: 3 [3080/5020 (61%)]\tLoss: 1.038039\n",
      "Train Epoch: 3 [3120/5020 (62%)]\tLoss: 1.147474\n",
      "Train Epoch: 3 [3160/5020 (63%)]\tLoss: 1.065021\n",
      "Train Epoch: 3 [3200/5020 (64%)]\tLoss: 1.137571\n",
      "Train Epoch: 3 [3240/5020 (65%)]\tLoss: 1.056304\n",
      "Train Epoch: 3 [3280/5020 (65%)]\tLoss: 1.105065\n",
      "Train Epoch: 3 [3320/5020 (66%)]\tLoss: 1.031859\n",
      "Train Epoch: 3 [3360/5020 (67%)]\tLoss: 1.065363\n",
      "Train Epoch: 3 [3400/5020 (68%)]\tLoss: 1.085902\n",
      "Train Epoch: 3 [3440/5020 (69%)]\tLoss: 1.053567\n",
      "Train Epoch: 3 [3480/5020 (69%)]\tLoss: 1.121343\n",
      "Train Epoch: 3 [3520/5020 (70%)]\tLoss: 1.088919\n",
      "Train Epoch: 3 [3560/5020 (71%)]\tLoss: 1.068267\n",
      "Train Epoch: 3 [3600/5020 (72%)]\tLoss: 1.054475\n",
      "Train Epoch: 3 [3640/5020 (73%)]\tLoss: 1.053271\n",
      "Train Epoch: 3 [3680/5020 (73%)]\tLoss: 1.077445\n",
      "Train Epoch: 3 [3720/5020 (74%)]\tLoss: 1.123843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3760/5020 (75%)]\tLoss: 1.030753\n",
      "Train Epoch: 3 [3800/5020 (76%)]\tLoss: 1.123324\n",
      "Train Epoch: 3 [3840/5020 (76%)]\tLoss: 1.122419\n",
      "Train Epoch: 3 [3880/5020 (77%)]\tLoss: 1.127764\n",
      "Train Epoch: 3 [3920/5020 (78%)]\tLoss: 1.072102\n",
      "Train Epoch: 3 [3960/5020 (79%)]\tLoss: 1.016986\n",
      "Train Epoch: 3 [4000/5020 (80%)]\tLoss: 1.027104\n",
      "Train Epoch: 3 [4040/5020 (80%)]\tLoss: 1.082389\n",
      "Train Epoch: 3 [4080/5020 (81%)]\tLoss: 1.064517\n",
      "Train Epoch: 3 [4120/5020 (82%)]\tLoss: 1.124285\n",
      "Train Epoch: 3 [4160/5020 (83%)]\tLoss: 1.160861\n",
      "Train Epoch: 3 [4200/5020 (84%)]\tLoss: 0.991466\n",
      "Train Epoch: 3 [4240/5020 (84%)]\tLoss: 1.103919\n",
      "Train Epoch: 3 [4280/5020 (85%)]\tLoss: 1.116560\n",
      "Train Epoch: 3 [4320/5020 (86%)]\tLoss: 1.016010\n",
      "Train Epoch: 3 [4360/5020 (87%)]\tLoss: 0.984327\n",
      "Train Epoch: 3 [4400/5020 (88%)]\tLoss: 1.063717\n",
      "Train Epoch: 3 [4440/5020 (88%)]\tLoss: 1.075110\n",
      "Train Epoch: 3 [4480/5020 (89%)]\tLoss: 1.080029\n",
      "Train Epoch: 3 [4520/5020 (90%)]\tLoss: 1.324852\n",
      "Train Epoch: 3 [4560/5020 (91%)]\tLoss: 1.015154\n",
      "Train Epoch: 3 [4600/5020 (92%)]\tLoss: 1.091257\n",
      "Train Epoch: 3 [4640/5020 (92%)]\tLoss: 1.039754\n",
      "Train Epoch: 3 [4680/5020 (93%)]\tLoss: 1.154329\n",
      "Train Epoch: 3 [4720/5020 (94%)]\tLoss: 1.010079\n",
      "Train Epoch: 3 [4760/5020 (95%)]\tLoss: 0.957998\n",
      "Train Epoch: 3 [4800/5020 (96%)]\tLoss: 1.209268\n",
      "Train Epoch: 3 [4840/5020 (96%)]\tLoss: 1.056401\n",
      "Train Epoch: 3 [4880/5020 (97%)]\tLoss: 1.136193\n",
      "Train Epoch: 3 [4920/5020 (98%)]\tLoss: 1.029966\n",
      "Train Epoch: 3 [4960/5020 (99%)]\tLoss: 1.036720\n",
      "Train Epoch: 3 [5000/5020 (100%)]\tLoss: 1.114958\n",
      "\n",
      "Test set: Avg. loss: 1.0799, Accuracy: 208/519 (40%)\n",
      "\n",
      "Train Epoch: 4 [0/5020 (0%)]\tLoss: 1.140403\n",
      "Train Epoch: 4 [40/5020 (1%)]\tLoss: 1.097804\n",
      "Train Epoch: 4 [80/5020 (2%)]\tLoss: 1.151015\n",
      "Train Epoch: 4 [120/5020 (2%)]\tLoss: 0.895952\n",
      "Train Epoch: 4 [160/5020 (3%)]\tLoss: 1.049740\n",
      "Train Epoch: 4 [200/5020 (4%)]\tLoss: 1.110840\n",
      "Train Epoch: 4 [240/5020 (5%)]\tLoss: 1.047011\n",
      "Train Epoch: 4 [280/5020 (6%)]\tLoss: 0.992507\n",
      "Train Epoch: 4 [320/5020 (6%)]\tLoss: 1.054769\n",
      "Train Epoch: 4 [360/5020 (7%)]\tLoss: 1.387448\n",
      "Train Epoch: 4 [400/5020 (8%)]\tLoss: 1.050399\n",
      "Train Epoch: 4 [440/5020 (9%)]\tLoss: 1.058022\n",
      "Train Epoch: 4 [480/5020 (10%)]\tLoss: 1.108812\n",
      "Train Epoch: 4 [520/5020 (10%)]\tLoss: 1.116546\n",
      "Train Epoch: 4 [560/5020 (11%)]\tLoss: 1.057164\n",
      "Train Epoch: 4 [600/5020 (12%)]\tLoss: 0.944603\n",
      "Train Epoch: 4 [640/5020 (13%)]\tLoss: 1.118283\n",
      "Train Epoch: 4 [680/5020 (14%)]\tLoss: 1.073927\n",
      "Train Epoch: 4 [720/5020 (14%)]\tLoss: 1.009330\n",
      "Train Epoch: 4 [760/5020 (15%)]\tLoss: 1.033777\n",
      "Train Epoch: 4 [800/5020 (16%)]\tLoss: 1.217106\n",
      "Train Epoch: 4 [840/5020 (17%)]\tLoss: 0.995483\n",
      "Train Epoch: 4 [880/5020 (18%)]\tLoss: 1.542282\n",
      "Train Epoch: 4 [920/5020 (18%)]\tLoss: 1.142654\n",
      "Train Epoch: 4 [960/5020 (19%)]\tLoss: 0.921490\n",
      "Train Epoch: 4 [1000/5020 (20%)]\tLoss: 1.295600\n",
      "Train Epoch: 4 [1040/5020 (21%)]\tLoss: 1.147206\n",
      "Train Epoch: 4 [1080/5020 (22%)]\tLoss: 1.074770\n",
      "Train Epoch: 4 [1120/5020 (22%)]\tLoss: 0.955841\n",
      "Train Epoch: 4 [1160/5020 (23%)]\tLoss: 1.234499\n",
      "Train Epoch: 4 [1200/5020 (24%)]\tLoss: 1.095424\n",
      "Train Epoch: 4 [1240/5020 (25%)]\tLoss: 1.066976\n",
      "Train Epoch: 4 [1280/5020 (25%)]\tLoss: 0.983675\n",
      "Train Epoch: 4 [1320/5020 (26%)]\tLoss: 1.103667\n",
      "Train Epoch: 4 [1360/5020 (27%)]\tLoss: 0.928285\n",
      "Train Epoch: 4 [1400/5020 (28%)]\tLoss: 1.065247\n",
      "Train Epoch: 4 [1440/5020 (29%)]\tLoss: 0.962610\n",
      "Train Epoch: 4 [1480/5020 (29%)]\tLoss: 0.791304\n",
      "Train Epoch: 4 [1520/5020 (30%)]\tLoss: 1.056322\n",
      "Train Epoch: 4 [1560/5020 (31%)]\tLoss: 1.057969\n",
      "Train Epoch: 4 [1600/5020 (32%)]\tLoss: 1.216397\n",
      "Train Epoch: 4 [1640/5020 (33%)]\tLoss: 1.054193\n",
      "Train Epoch: 4 [1680/5020 (33%)]\tLoss: 1.136151\n",
      "Train Epoch: 4 [1720/5020 (34%)]\tLoss: 0.972058\n",
      "Train Epoch: 4 [1760/5020 (35%)]\tLoss: 0.932141\n",
      "Train Epoch: 4 [1800/5020 (36%)]\tLoss: 0.803288\n",
      "Train Epoch: 4 [1840/5020 (37%)]\tLoss: 1.077904\n",
      "Train Epoch: 4 [1880/5020 (37%)]\tLoss: 1.097778\n",
      "Train Epoch: 4 [1920/5020 (38%)]\tLoss: 0.987165\n",
      "Train Epoch: 4 [1960/5020 (39%)]\tLoss: 1.169171\n",
      "Train Epoch: 4 [2000/5020 (40%)]\tLoss: 1.140823\n",
      "Train Epoch: 4 [2040/5020 (41%)]\tLoss: 1.039580\n",
      "Train Epoch: 4 [2080/5020 (41%)]\tLoss: 1.067756\n",
      "Train Epoch: 4 [2120/5020 (42%)]\tLoss: 1.108519\n",
      "Train Epoch: 4 [2160/5020 (43%)]\tLoss: 1.020320\n",
      "Train Epoch: 4 [2200/5020 (44%)]\tLoss: 0.919276\n",
      "Train Epoch: 4 [2240/5020 (45%)]\tLoss: 1.054127\n",
      "Train Epoch: 4 [2280/5020 (45%)]\tLoss: 1.118510\n",
      "Train Epoch: 4 [2320/5020 (46%)]\tLoss: 1.158288\n",
      "Train Epoch: 4 [2360/5020 (47%)]\tLoss: 1.137938\n",
      "Train Epoch: 4 [2400/5020 (48%)]\tLoss: 1.044935\n",
      "Train Epoch: 4 [2440/5020 (49%)]\tLoss: 1.090724\n",
      "Train Epoch: 4 [2480/5020 (49%)]\tLoss: 1.217451\n",
      "Train Epoch: 4 [2520/5020 (50%)]\tLoss: 0.983270\n",
      "Train Epoch: 4 [2560/5020 (51%)]\tLoss: 1.095253\n",
      "Train Epoch: 4 [2600/5020 (52%)]\tLoss: 1.163838\n",
      "Train Epoch: 4 [2640/5020 (53%)]\tLoss: 1.113298\n",
      "Train Epoch: 4 [2680/5020 (53%)]\tLoss: 1.065091\n",
      "Train Epoch: 4 [2720/5020 (54%)]\tLoss: 1.078651\n",
      "Train Epoch: 4 [2760/5020 (55%)]\tLoss: 0.823331\n",
      "Train Epoch: 4 [2800/5020 (56%)]\tLoss: 1.096011\n",
      "Train Epoch: 4 [2840/5020 (57%)]\tLoss: 0.904576\n",
      "Train Epoch: 4 [2880/5020 (57%)]\tLoss: 0.985217\n",
      "Train Epoch: 4 [2920/5020 (58%)]\tLoss: 1.062703\n",
      "Train Epoch: 4 [2960/5020 (59%)]\tLoss: 0.934899\n",
      "Train Epoch: 4 [3000/5020 (60%)]\tLoss: 1.192820\n",
      "Train Epoch: 4 [3040/5020 (61%)]\tLoss: 1.099120\n",
      "Train Epoch: 4 [3080/5020 (61%)]\tLoss: 0.988675\n",
      "Train Epoch: 4 [3120/5020 (62%)]\tLoss: 1.164733\n",
      "Train Epoch: 4 [3160/5020 (63%)]\tLoss: 1.003901\n",
      "Train Epoch: 4 [3200/5020 (64%)]\tLoss: 1.055217\n",
      "Train Epoch: 4 [3240/5020 (65%)]\tLoss: 1.111977\n",
      "Train Epoch: 4 [3280/5020 (65%)]\tLoss: 0.990396\n",
      "Train Epoch: 4 [3320/5020 (66%)]\tLoss: 0.936399\n",
      "Train Epoch: 4 [3360/5020 (67%)]\tLoss: 0.900006\n",
      "Train Epoch: 4 [3400/5020 (68%)]\tLoss: 1.012905\n",
      "Train Epoch: 4 [3440/5020 (69%)]\tLoss: 1.015727\n",
      "Train Epoch: 4 [3480/5020 (69%)]\tLoss: 1.189255\n",
      "Train Epoch: 4 [3520/5020 (70%)]\tLoss: 0.826039\n",
      "Train Epoch: 4 [3560/5020 (71%)]\tLoss: 0.990736\n",
      "Train Epoch: 4 [3600/5020 (72%)]\tLoss: 1.136961\n",
      "Train Epoch: 4 [3640/5020 (73%)]\tLoss: 1.043803\n",
      "Train Epoch: 4 [3680/5020 (73%)]\tLoss: 1.207119\n",
      "Train Epoch: 4 [3720/5020 (74%)]\tLoss: 1.174054\n",
      "Train Epoch: 4 [3760/5020 (75%)]\tLoss: 0.998895\n",
      "Train Epoch: 4 [3800/5020 (76%)]\tLoss: 1.050628\n",
      "Train Epoch: 4 [3840/5020 (76%)]\tLoss: 0.920493\n",
      "Train Epoch: 4 [3880/5020 (77%)]\tLoss: 1.020430\n",
      "Train Epoch: 4 [3920/5020 (78%)]\tLoss: 0.907556\n",
      "Train Epoch: 4 [3960/5020 (79%)]\tLoss: 0.865807\n",
      "Train Epoch: 4 [4000/5020 (80%)]\tLoss: 1.137477\n",
      "Train Epoch: 4 [4040/5020 (80%)]\tLoss: 1.075507\n",
      "Train Epoch: 4 [4080/5020 (81%)]\tLoss: 1.084999\n",
      "Train Epoch: 4 [4120/5020 (82%)]\tLoss: 1.165818\n",
      "Train Epoch: 4 [4160/5020 (83%)]\tLoss: 0.960437\n",
      "Train Epoch: 4 [4200/5020 (84%)]\tLoss: 0.980161\n",
      "Train Epoch: 4 [4240/5020 (84%)]\tLoss: 1.217926\n",
      "Train Epoch: 4 [4280/5020 (85%)]\tLoss: 1.003308\n",
      "Train Epoch: 4 [4320/5020 (86%)]\tLoss: 0.990792\n",
      "Train Epoch: 4 [4360/5020 (87%)]\tLoss: 1.045106\n",
      "Train Epoch: 4 [4400/5020 (88%)]\tLoss: 1.009362\n",
      "Train Epoch: 4 [4440/5020 (88%)]\tLoss: 0.973453\n",
      "Train Epoch: 4 [4480/5020 (89%)]\tLoss: 1.303616\n",
      "Train Epoch: 4 [4520/5020 (90%)]\tLoss: 1.099280\n",
      "Train Epoch: 4 [4560/5020 (91%)]\tLoss: 0.794931\n",
      "Train Epoch: 4 [4600/5020 (92%)]\tLoss: 1.201184\n",
      "Train Epoch: 4 [4640/5020 (92%)]\tLoss: 0.780965\n",
      "Train Epoch: 4 [4680/5020 (93%)]\tLoss: 1.072025\n",
      "Train Epoch: 4 [4720/5020 (94%)]\tLoss: 0.888286\n",
      "Train Epoch: 4 [4760/5020 (95%)]\tLoss: 1.119330\n",
      "Train Epoch: 4 [4800/5020 (96%)]\tLoss: 1.201641\n",
      "Train Epoch: 4 [4840/5020 (96%)]\tLoss: 0.909745\n",
      "Train Epoch: 4 [4880/5020 (97%)]\tLoss: 1.221364\n",
      "Train Epoch: 4 [4920/5020 (98%)]\tLoss: 1.130618\n",
      "Train Epoch: 4 [4960/5020 (99%)]\tLoss: 1.019575\n",
      "Train Epoch: 4 [5000/5020 (100%)]\tLoss: 0.836234\n",
      "\n",
      "Test set: Avg. loss: 1.0632, Accuracy: 246/519 (47%)\n",
      "\n",
      "Train Epoch: 5 [0/5020 (0%)]\tLoss: 1.118955\n",
      "Train Epoch: 5 [40/5020 (1%)]\tLoss: 1.140381\n",
      "Train Epoch: 5 [80/5020 (2%)]\tLoss: 0.938658\n",
      "Train Epoch: 5 [120/5020 (2%)]\tLoss: 1.276451\n",
      "Train Epoch: 5 [160/5020 (3%)]\tLoss: 1.128244\n",
      "Train Epoch: 5 [200/5020 (4%)]\tLoss: 1.184255\n",
      "Train Epoch: 5 [240/5020 (5%)]\tLoss: 0.992071\n",
      "Train Epoch: 5 [280/5020 (6%)]\tLoss: 0.930121\n",
      "Train Epoch: 5 [320/5020 (6%)]\tLoss: 1.237458\n",
      "Train Epoch: 5 [360/5020 (7%)]\tLoss: 0.949661\n",
      "Train Epoch: 5 [400/5020 (8%)]\tLoss: 1.136611\n",
      "Train Epoch: 5 [440/5020 (9%)]\tLoss: 1.089124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [480/5020 (10%)]\tLoss: 0.868047\n",
      "Train Epoch: 5 [520/5020 (10%)]\tLoss: 0.853139\n",
      "Train Epoch: 5 [560/5020 (11%)]\tLoss: 1.161170\n",
      "Train Epoch: 5 [600/5020 (12%)]\tLoss: 1.079843\n",
      "Train Epoch: 5 [640/5020 (13%)]\tLoss: 1.047363\n",
      "Train Epoch: 5 [680/5020 (14%)]\tLoss: 1.083632\n",
      "Train Epoch: 5 [720/5020 (14%)]\tLoss: 1.130281\n",
      "Train Epoch: 5 [760/5020 (15%)]\tLoss: 0.912790\n",
      "Train Epoch: 5 [800/5020 (16%)]\tLoss: 0.995339\n",
      "Train Epoch: 5 [840/5020 (17%)]\tLoss: 1.185047\n",
      "Train Epoch: 5 [880/5020 (18%)]\tLoss: 0.926134\n",
      "Train Epoch: 5 [920/5020 (18%)]\tLoss: 1.228569\n",
      "Train Epoch: 5 [960/5020 (19%)]\tLoss: 1.088405\n",
      "Train Epoch: 5 [1000/5020 (20%)]\tLoss: 0.941848\n",
      "Train Epoch: 5 [1040/5020 (21%)]\tLoss: 1.170000\n",
      "Train Epoch: 5 [1080/5020 (22%)]\tLoss: 1.241540\n",
      "Train Epoch: 5 [1120/5020 (22%)]\tLoss: 1.115193\n",
      "Train Epoch: 5 [1160/5020 (23%)]\tLoss: 1.075621\n",
      "Train Epoch: 5 [1200/5020 (24%)]\tLoss: 1.091353\n",
      "Train Epoch: 5 [1240/5020 (25%)]\tLoss: 1.156552\n",
      "Train Epoch: 5 [1280/5020 (25%)]\tLoss: 1.062790\n",
      "Train Epoch: 5 [1320/5020 (26%)]\tLoss: 0.990350\n",
      "Train Epoch: 5 [1360/5020 (27%)]\tLoss: 0.948542\n",
      "Train Epoch: 5 [1400/5020 (28%)]\tLoss: 1.082753\n",
      "Train Epoch: 5 [1440/5020 (29%)]\tLoss: 0.787679\n",
      "Train Epoch: 5 [1480/5020 (29%)]\tLoss: 1.017826\n",
      "Train Epoch: 5 [1520/5020 (30%)]\tLoss: 1.224843\n",
      "Train Epoch: 5 [1560/5020 (31%)]\tLoss: 1.033599\n",
      "Train Epoch: 5 [1600/5020 (32%)]\tLoss: 0.869470\n",
      "Train Epoch: 5 [1640/5020 (33%)]\tLoss: 1.477295\n",
      "Train Epoch: 5 [1680/5020 (33%)]\tLoss: 1.021461\n",
      "Train Epoch: 5 [1720/5020 (34%)]\tLoss: 1.055479\n",
      "Train Epoch: 5 [1760/5020 (35%)]\tLoss: 1.048826\n",
      "Train Epoch: 5 [1800/5020 (36%)]\tLoss: 1.173100\n",
      "Train Epoch: 5 [1840/5020 (37%)]\tLoss: 1.045634\n",
      "Train Epoch: 5 [1880/5020 (37%)]\tLoss: 1.202354\n",
      "Train Epoch: 5 [1920/5020 (38%)]\tLoss: 1.155991\n",
      "Train Epoch: 5 [1960/5020 (39%)]\tLoss: 1.033464\n",
      "Train Epoch: 5 [2000/5020 (40%)]\tLoss: 1.042748\n",
      "Train Epoch: 5 [2040/5020 (41%)]\tLoss: 1.134118\n",
      "Train Epoch: 5 [2080/5020 (41%)]\tLoss: 1.130788\n",
      "Train Epoch: 5 [2120/5020 (42%)]\tLoss: 1.138805\n",
      "Train Epoch: 5 [2160/5020 (43%)]\tLoss: 1.110733\n",
      "Train Epoch: 5 [2200/5020 (44%)]\tLoss: 0.985623\n",
      "Train Epoch: 5 [2240/5020 (45%)]\tLoss: 1.074719\n",
      "Train Epoch: 5 [2280/5020 (45%)]\tLoss: 1.027193\n",
      "Train Epoch: 5 [2320/5020 (46%)]\tLoss: 1.061809\n",
      "Train Epoch: 5 [2360/5020 (47%)]\tLoss: 1.027448\n",
      "Train Epoch: 5 [2400/5020 (48%)]\tLoss: 1.058517\n",
      "Train Epoch: 5 [2440/5020 (49%)]\tLoss: 1.041803\n",
      "Train Epoch: 5 [2480/5020 (49%)]\tLoss: 0.992746\n",
      "Train Epoch: 5 [2520/5020 (50%)]\tLoss: 1.051128\n",
      "Train Epoch: 5 [2560/5020 (51%)]\tLoss: 1.247319\n",
      "Train Epoch: 5 [2600/5020 (52%)]\tLoss: 1.073439\n",
      "Train Epoch: 5 [2640/5020 (53%)]\tLoss: 0.929300\n",
      "Train Epoch: 5 [2680/5020 (53%)]\tLoss: 1.205181\n",
      "Train Epoch: 5 [2720/5020 (54%)]\tLoss: 1.074239\n",
      "Train Epoch: 5 [2760/5020 (55%)]\tLoss: 0.957519\n",
      "Train Epoch: 5 [2800/5020 (56%)]\tLoss: 0.841688\n",
      "Train Epoch: 5 [2840/5020 (57%)]\tLoss: 1.223463\n",
      "Train Epoch: 5 [2880/5020 (57%)]\tLoss: 1.176200\n",
      "Train Epoch: 5 [2920/5020 (58%)]\tLoss: 1.089749\n",
      "Train Epoch: 5 [2960/5020 (59%)]\tLoss: 0.923083\n",
      "Train Epoch: 5 [3000/5020 (60%)]\tLoss: 1.185410\n",
      "Train Epoch: 5 [3040/5020 (61%)]\tLoss: 1.047880\n",
      "Train Epoch: 5 [3080/5020 (61%)]\tLoss: 1.150668\n",
      "Train Epoch: 5 [3120/5020 (62%)]\tLoss: 1.078349\n",
      "Train Epoch: 5 [3160/5020 (63%)]\tLoss: 1.315995\n",
      "Train Epoch: 5 [3200/5020 (64%)]\tLoss: 1.073852\n",
      "Train Epoch: 5 [3240/5020 (65%)]\tLoss: 0.915445\n",
      "Train Epoch: 5 [3280/5020 (65%)]\tLoss: 1.066005\n",
      "Train Epoch: 5 [3320/5020 (66%)]\tLoss: 1.043807\n",
      "Train Epoch: 5 [3360/5020 (67%)]\tLoss: 1.105822\n",
      "Train Epoch: 5 [3400/5020 (68%)]\tLoss: 0.982689\n",
      "Train Epoch: 5 [3440/5020 (69%)]\tLoss: 0.929241\n",
      "Train Epoch: 5 [3480/5020 (69%)]\tLoss: 0.832678\n",
      "Train Epoch: 5 [3520/5020 (70%)]\tLoss: 1.087114\n",
      "Train Epoch: 5 [3560/5020 (71%)]\tLoss: 0.964689\n",
      "Train Epoch: 5 [3600/5020 (72%)]\tLoss: 0.925164\n",
      "Train Epoch: 5 [3640/5020 (73%)]\tLoss: 1.550525\n",
      "Train Epoch: 5 [3680/5020 (73%)]\tLoss: 0.913046\n",
      "Train Epoch: 5 [3720/5020 (74%)]\tLoss: 0.959894\n",
      "Train Epoch: 5 [3760/5020 (75%)]\tLoss: 1.105442\n",
      "Train Epoch: 5 [3800/5020 (76%)]\tLoss: 0.820085\n",
      "Train Epoch: 5 [3840/5020 (76%)]\tLoss: 1.274160\n",
      "Train Epoch: 5 [3880/5020 (77%)]\tLoss: 1.073121\n",
      "Train Epoch: 5 [3920/5020 (78%)]\tLoss: 1.001982\n",
      "Train Epoch: 5 [3960/5020 (79%)]\tLoss: 1.180660\n",
      "Train Epoch: 5 [4000/5020 (80%)]\tLoss: 1.124434\n",
      "Train Epoch: 5 [4040/5020 (80%)]\tLoss: 1.117136\n",
      "Train Epoch: 5 [4080/5020 (81%)]\tLoss: 0.984522\n",
      "Train Epoch: 5 [4120/5020 (82%)]\tLoss: 0.836067\n",
      "Train Epoch: 5 [4160/5020 (83%)]\tLoss: 0.981496\n",
      "Train Epoch: 5 [4200/5020 (84%)]\tLoss: 1.101628\n",
      "Train Epoch: 5 [4240/5020 (84%)]\tLoss: 1.080695\n",
      "Train Epoch: 5 [4280/5020 (85%)]\tLoss: 0.959604\n",
      "Train Epoch: 5 [4320/5020 (86%)]\tLoss: 1.082463\n",
      "Train Epoch: 5 [4360/5020 (87%)]\tLoss: 1.072019\n",
      "Train Epoch: 5 [4400/5020 (88%)]\tLoss: 1.468677\n",
      "Train Epoch: 5 [4440/5020 (88%)]\tLoss: 0.952844\n",
      "Train Epoch: 5 [4480/5020 (89%)]\tLoss: 1.133870\n",
      "Train Epoch: 5 [4520/5020 (90%)]\tLoss: 0.975845\n",
      "Train Epoch: 5 [4560/5020 (91%)]\tLoss: 1.129154\n",
      "Train Epoch: 5 [4600/5020 (92%)]\tLoss: 1.502383\n",
      "Train Epoch: 5 [4640/5020 (92%)]\tLoss: 1.135297\n",
      "Train Epoch: 5 [4680/5020 (93%)]\tLoss: 1.035995\n",
      "Train Epoch: 5 [4720/5020 (94%)]\tLoss: 1.095644\n",
      "Train Epoch: 5 [4760/5020 (95%)]\tLoss: 1.093658\n",
      "Train Epoch: 5 [4800/5020 (96%)]\tLoss: 1.022346\n",
      "Train Epoch: 5 [4840/5020 (96%)]\tLoss: 0.779005\n",
      "Train Epoch: 5 [4880/5020 (97%)]\tLoss: 1.106763\n",
      "Train Epoch: 5 [4920/5020 (98%)]\tLoss: 1.032777\n",
      "Train Epoch: 5 [4960/5020 (99%)]\tLoss: 0.997831\n",
      "Train Epoch: 5 [5000/5020 (100%)]\tLoss: 1.118252\n",
      "\n",
      "Test set: Avg. loss: 1.0436, Accuracy: 248/519 (48%)\n",
      "\n",
      "Train Epoch: 6 [0/5020 (0%)]\tLoss: 1.082323\n",
      "Train Epoch: 6 [40/5020 (1%)]\tLoss: 1.047881\n",
      "Train Epoch: 6 [80/5020 (2%)]\tLoss: 0.935005\n",
      "Train Epoch: 6 [120/5020 (2%)]\tLoss: 1.197589\n",
      "Train Epoch: 6 [160/5020 (3%)]\tLoss: 0.717323\n",
      "Train Epoch: 6 [200/5020 (4%)]\tLoss: 1.043657\n",
      "Train Epoch: 6 [240/5020 (5%)]\tLoss: 1.043094\n",
      "Train Epoch: 6 [280/5020 (6%)]\tLoss: 0.959461\n",
      "Train Epoch: 6 [320/5020 (6%)]\tLoss: 1.133330\n",
      "Train Epoch: 6 [360/5020 (7%)]\tLoss: 1.079309\n",
      "Train Epoch: 6 [400/5020 (8%)]\tLoss: 0.909805\n",
      "Train Epoch: 6 [440/5020 (9%)]\tLoss: 1.305493\n",
      "Train Epoch: 6 [480/5020 (10%)]\tLoss: 0.922854\n",
      "Train Epoch: 6 [520/5020 (10%)]\tLoss: 1.105519\n",
      "Train Epoch: 6 [560/5020 (11%)]\tLoss: 0.976424\n",
      "Train Epoch: 6 [600/5020 (12%)]\tLoss: 1.040897\n",
      "Train Epoch: 6 [640/5020 (13%)]\tLoss: 1.011233\n",
      "Train Epoch: 6 [680/5020 (14%)]\tLoss: 1.288626\n",
      "Train Epoch: 6 [720/5020 (14%)]\tLoss: 1.172040\n",
      "Train Epoch: 6 [760/5020 (15%)]\tLoss: 0.902023\n",
      "Train Epoch: 6 [800/5020 (16%)]\tLoss: 0.876102\n",
      "Train Epoch: 6 [840/5020 (17%)]\tLoss: 0.782060\n",
      "Train Epoch: 6 [880/5020 (18%)]\tLoss: 0.758778\n",
      "Train Epoch: 6 [920/5020 (18%)]\tLoss: 1.086527\n",
      "Train Epoch: 6 [960/5020 (19%)]\tLoss: 1.107807\n",
      "Train Epoch: 6 [1000/5020 (20%)]\tLoss: 1.050141\n",
      "Train Epoch: 6 [1040/5020 (21%)]\tLoss: 1.113354\n",
      "Train Epoch: 6 [1080/5020 (22%)]\tLoss: 1.072568\n",
      "Train Epoch: 6 [1120/5020 (22%)]\tLoss: 1.100837\n",
      "Train Epoch: 6 [1160/5020 (23%)]\tLoss: 1.052885\n",
      "Train Epoch: 6 [1200/5020 (24%)]\tLoss: 1.067277\n",
      "Train Epoch: 6 [1240/5020 (25%)]\tLoss: 1.108578\n",
      "Train Epoch: 6 [1280/5020 (25%)]\tLoss: 0.938812\n",
      "Train Epoch: 6 [1320/5020 (26%)]\tLoss: 1.051709\n",
      "Train Epoch: 6 [1360/5020 (27%)]\tLoss: 1.093952\n",
      "Train Epoch: 6 [1400/5020 (28%)]\tLoss: 1.197257\n",
      "Train Epoch: 6 [1440/5020 (29%)]\tLoss: 1.151815\n",
      "Train Epoch: 6 [1480/5020 (29%)]\tLoss: 1.044482\n",
      "Train Epoch: 6 [1520/5020 (30%)]\tLoss: 1.335785\n",
      "Train Epoch: 6 [1560/5020 (31%)]\tLoss: 1.095840\n",
      "Train Epoch: 6 [1600/5020 (32%)]\tLoss: 0.968550\n",
      "Train Epoch: 6 [1640/5020 (33%)]\tLoss: 1.120582\n",
      "Train Epoch: 6 [1680/5020 (33%)]\tLoss: 1.120064\n",
      "Train Epoch: 6 [1720/5020 (34%)]\tLoss: 0.951944\n",
      "Train Epoch: 6 [1760/5020 (35%)]\tLoss: 1.034818\n",
      "Train Epoch: 6 [1800/5020 (36%)]\tLoss: 1.196358\n",
      "Train Epoch: 6 [1840/5020 (37%)]\tLoss: 0.862691\n",
      "Train Epoch: 6 [1880/5020 (37%)]\tLoss: 1.047118\n",
      "Train Epoch: 6 [1920/5020 (38%)]\tLoss: 1.093422\n",
      "Train Epoch: 6 [1960/5020 (39%)]\tLoss: 1.019796\n",
      "Train Epoch: 6 [2000/5020 (40%)]\tLoss: 1.073466\n",
      "Train Epoch: 6 [2040/5020 (41%)]\tLoss: 0.950274\n",
      "Train Epoch: 6 [2080/5020 (41%)]\tLoss: 1.084111\n",
      "Train Epoch: 6 [2120/5020 (42%)]\tLoss: 0.979256\n",
      "Train Epoch: 6 [2160/5020 (43%)]\tLoss: 1.065719\n",
      "Train Epoch: 6 [2200/5020 (44%)]\tLoss: 0.918208\n",
      "Train Epoch: 6 [2240/5020 (45%)]\tLoss: 0.962132\n",
      "Train Epoch: 6 [2280/5020 (45%)]\tLoss: 0.782856\n",
      "Train Epoch: 6 [2320/5020 (46%)]\tLoss: 1.034228\n",
      "Train Epoch: 6 [2360/5020 (47%)]\tLoss: 1.010340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [2400/5020 (48%)]\tLoss: 0.991801\n",
      "Train Epoch: 6 [2440/5020 (49%)]\tLoss: 1.492308\n",
      "Train Epoch: 6 [2480/5020 (49%)]\tLoss: 1.122936\n",
      "Train Epoch: 6 [2520/5020 (50%)]\tLoss: 0.937307\n",
      "Train Epoch: 6 [2560/5020 (51%)]\tLoss: 1.027027\n",
      "Train Epoch: 6 [2600/5020 (52%)]\tLoss: 0.942068\n",
      "Train Epoch: 6 [2640/5020 (53%)]\tLoss: 0.769258\n",
      "Train Epoch: 6 [2680/5020 (53%)]\tLoss: 1.369637\n",
      "Train Epoch: 6 [2720/5020 (54%)]\tLoss: 1.005214\n",
      "Train Epoch: 6 [2760/5020 (55%)]\tLoss: 1.116015\n",
      "Train Epoch: 6 [2800/5020 (56%)]\tLoss: 1.093661\n",
      "Train Epoch: 6 [2840/5020 (57%)]\tLoss: 0.906093\n",
      "Train Epoch: 6 [2880/5020 (57%)]\tLoss: 1.184712\n",
      "Train Epoch: 6 [2920/5020 (58%)]\tLoss: 0.627637\n",
      "Train Epoch: 6 [2960/5020 (59%)]\tLoss: 1.024780\n",
      "Train Epoch: 6 [3000/5020 (60%)]\tLoss: 1.037341\n",
      "Train Epoch: 6 [3040/5020 (61%)]\tLoss: 1.175680\n",
      "Train Epoch: 6 [3080/5020 (61%)]\tLoss: 1.635156\n",
      "Train Epoch: 6 [3120/5020 (62%)]\tLoss: 1.087824\n",
      "Train Epoch: 6 [3160/5020 (63%)]\tLoss: 1.188849\n",
      "Train Epoch: 6 [3200/5020 (64%)]\tLoss: 0.921755\n",
      "Train Epoch: 6 [3240/5020 (65%)]\tLoss: 0.877919\n",
      "Train Epoch: 6 [3280/5020 (65%)]\tLoss: 1.029858\n",
      "Train Epoch: 6 [3320/5020 (66%)]\tLoss: 0.871687\n",
      "Train Epoch: 6 [3360/5020 (67%)]\tLoss: 1.059473\n",
      "Train Epoch: 6 [3400/5020 (68%)]\tLoss: 1.323564\n",
      "Train Epoch: 6 [3440/5020 (69%)]\tLoss: 1.061517\n",
      "Train Epoch: 6 [3480/5020 (69%)]\tLoss: 1.005516\n",
      "Train Epoch: 6 [3520/5020 (70%)]\tLoss: 1.270206\n",
      "Train Epoch: 6 [3560/5020 (71%)]\tLoss: 1.176861\n",
      "Train Epoch: 6 [3600/5020 (72%)]\tLoss: 0.928811\n",
      "Train Epoch: 6 [3640/5020 (73%)]\tLoss: 1.314806\n",
      "Train Epoch: 6 [3680/5020 (73%)]\tLoss: 1.337608\n",
      "Train Epoch: 6 [3720/5020 (74%)]\tLoss: 1.008712\n",
      "Train Epoch: 6 [3760/5020 (75%)]\tLoss: 1.197302\n",
      "Train Epoch: 6 [3800/5020 (76%)]\tLoss: 0.984848\n",
      "Train Epoch: 6 [3840/5020 (76%)]\tLoss: 0.915802\n",
      "Train Epoch: 6 [3880/5020 (77%)]\tLoss: 0.989158\n",
      "Train Epoch: 6 [3920/5020 (78%)]\tLoss: 0.832024\n",
      "Train Epoch: 6 [3960/5020 (79%)]\tLoss: 0.982014\n",
      "Train Epoch: 6 [4000/5020 (80%)]\tLoss: 1.343326\n",
      "Train Epoch: 6 [4040/5020 (80%)]\tLoss: 1.063481\n",
      "Train Epoch: 6 [4080/5020 (81%)]\tLoss: 0.814571\n",
      "Train Epoch: 6 [4120/5020 (82%)]\tLoss: 1.296015\n",
      "Train Epoch: 6 [4160/5020 (83%)]\tLoss: 1.070266\n",
      "Train Epoch: 6 [4200/5020 (84%)]\tLoss: 0.935727\n",
      "Train Epoch: 6 [4240/5020 (84%)]\tLoss: 1.071724\n",
      "Train Epoch: 6 [4280/5020 (85%)]\tLoss: 0.723302\n",
      "Train Epoch: 6 [4320/5020 (86%)]\tLoss: 0.847648\n",
      "Train Epoch: 6 [4360/5020 (87%)]\tLoss: 0.918034\n",
      "Train Epoch: 6 [4400/5020 (88%)]\tLoss: 0.898266\n",
      "Train Epoch: 6 [4440/5020 (88%)]\tLoss: 1.548681\n",
      "Train Epoch: 6 [4480/5020 (89%)]\tLoss: 1.136889\n",
      "Train Epoch: 6 [4520/5020 (90%)]\tLoss: 0.912599\n",
      "Train Epoch: 6 [4560/5020 (91%)]\tLoss: 1.098318\n",
      "Train Epoch: 6 [4600/5020 (92%)]\tLoss: 1.258814\n",
      "Train Epoch: 6 [4640/5020 (92%)]\tLoss: 0.815570\n",
      "Train Epoch: 6 [4680/5020 (93%)]\tLoss: 1.150843\n",
      "Train Epoch: 6 [4720/5020 (94%)]\tLoss: 1.108754\n",
      "Train Epoch: 6 [4760/5020 (95%)]\tLoss: 1.022137\n",
      "Train Epoch: 6 [4800/5020 (96%)]\tLoss: 1.246168\n",
      "Train Epoch: 6 [4840/5020 (96%)]\tLoss: 0.916399\n",
      "Train Epoch: 6 [4880/5020 (97%)]\tLoss: 1.199672\n",
      "Train Epoch: 6 [4920/5020 (98%)]\tLoss: 1.006191\n",
      "Train Epoch: 6 [4960/5020 (99%)]\tLoss: 0.908253\n",
      "Train Epoch: 6 [5000/5020 (100%)]\tLoss: 1.019649\n",
      "\n",
      "Test set: Avg. loss: 1.0494, Accuracy: 239/519 (46%)\n",
      "\n",
      "Train Epoch: 7 [0/5020 (0%)]\tLoss: 0.817550\n",
      "Train Epoch: 7 [40/5020 (1%)]\tLoss: 1.114292\n",
      "Train Epoch: 7 [80/5020 (2%)]\tLoss: 1.043321\n",
      "Train Epoch: 7 [120/5020 (2%)]\tLoss: 1.179948\n",
      "Train Epoch: 7 [160/5020 (3%)]\tLoss: 0.915622\n",
      "Train Epoch: 7 [200/5020 (4%)]\tLoss: 0.966124\n",
      "Train Epoch: 7 [240/5020 (5%)]\tLoss: 0.983895\n",
      "Train Epoch: 7 [280/5020 (6%)]\tLoss: 1.096828\n",
      "Train Epoch: 7 [320/5020 (6%)]\tLoss: 1.090332\n",
      "Train Epoch: 7 [360/5020 (7%)]\tLoss: 0.825458\n",
      "Train Epoch: 7 [400/5020 (8%)]\tLoss: 0.836419\n",
      "Train Epoch: 7 [440/5020 (9%)]\tLoss: 1.124933\n",
      "Train Epoch: 7 [480/5020 (10%)]\tLoss: 0.911447\n",
      "Train Epoch: 7 [520/5020 (10%)]\tLoss: 0.979569\n",
      "Train Epoch: 7 [560/5020 (11%)]\tLoss: 0.947262\n",
      "Train Epoch: 7 [600/5020 (12%)]\tLoss: 1.092411\n",
      "Train Epoch: 7 [640/5020 (13%)]\tLoss: 1.023274\n",
      "Train Epoch: 7 [680/5020 (14%)]\tLoss: 1.220328\n",
      "Train Epoch: 7 [720/5020 (14%)]\tLoss: 1.002632\n",
      "Train Epoch: 7 [760/5020 (15%)]\tLoss: 1.267737\n",
      "Train Epoch: 7 [800/5020 (16%)]\tLoss: 0.953679\n",
      "Train Epoch: 7 [840/5020 (17%)]\tLoss: 1.142938\n",
      "Train Epoch: 7 [880/5020 (18%)]\tLoss: 1.045971\n",
      "Train Epoch: 7 [920/5020 (18%)]\tLoss: 1.030900\n",
      "Train Epoch: 7 [960/5020 (19%)]\tLoss: 1.144461\n",
      "Train Epoch: 7 [1000/5020 (20%)]\tLoss: 1.247753\n",
      "Train Epoch: 7 [1040/5020 (21%)]\tLoss: 1.062979\n",
      "Train Epoch: 7 [1080/5020 (22%)]\tLoss: 1.126547\n",
      "Train Epoch: 7 [1120/5020 (22%)]\tLoss: 0.881637\n",
      "Train Epoch: 7 [1160/5020 (23%)]\tLoss: 1.315961\n",
      "Train Epoch: 7 [1200/5020 (24%)]\tLoss: 0.915691\n",
      "Train Epoch: 7 [1240/5020 (25%)]\tLoss: 1.022749\n",
      "Train Epoch: 7 [1280/5020 (25%)]\tLoss: 1.120142\n",
      "Train Epoch: 7 [1320/5020 (26%)]\tLoss: 1.140503\n",
      "Train Epoch: 7 [1360/5020 (27%)]\tLoss: 0.949596\n",
      "Train Epoch: 7 [1400/5020 (28%)]\tLoss: 1.420808\n",
      "Train Epoch: 7 [1440/5020 (29%)]\tLoss: 1.131492\n",
      "Train Epoch: 7 [1480/5020 (29%)]\tLoss: 1.085215\n",
      "Train Epoch: 7 [1520/5020 (30%)]\tLoss: 0.940453\n",
      "Train Epoch: 7 [1560/5020 (31%)]\tLoss: 0.914526\n",
      "Train Epoch: 7 [1600/5020 (32%)]\tLoss: 1.014546\n",
      "Train Epoch: 7 [1640/5020 (33%)]\tLoss: 1.052811\n",
      "Train Epoch: 7 [1680/5020 (33%)]\tLoss: 0.994462\n",
      "Train Epoch: 7 [1720/5020 (34%)]\tLoss: 1.175657\n",
      "Train Epoch: 7 [1760/5020 (35%)]\tLoss: 1.076348\n",
      "Train Epoch: 7 [1800/5020 (36%)]\tLoss: 1.133873\n",
      "Train Epoch: 7 [1840/5020 (37%)]\tLoss: 1.048401\n",
      "Train Epoch: 7 [1880/5020 (37%)]\tLoss: 1.053579\n",
      "Train Epoch: 7 [1920/5020 (38%)]\tLoss: 1.107289\n",
      "Train Epoch: 7 [1960/5020 (39%)]\tLoss: 0.937407\n",
      "Train Epoch: 7 [2000/5020 (40%)]\tLoss: 1.053872\n",
      "Train Epoch: 7 [2040/5020 (41%)]\tLoss: 1.244079\n",
      "Train Epoch: 7 [2080/5020 (41%)]\tLoss: 0.945269\n",
      "Train Epoch: 7 [2120/5020 (42%)]\tLoss: 0.895965\n",
      "Train Epoch: 7 [2160/5020 (43%)]\tLoss: 1.047862\n",
      "Train Epoch: 7 [2200/5020 (44%)]\tLoss: 1.158817\n",
      "Train Epoch: 7 [2240/5020 (45%)]\tLoss: 1.446044\n",
      "Train Epoch: 7 [2280/5020 (45%)]\tLoss: 1.035366\n",
      "Train Epoch: 7 [2320/5020 (46%)]\tLoss: 1.001269\n",
      "Train Epoch: 7 [2360/5020 (47%)]\tLoss: 0.990797\n",
      "Train Epoch: 7 [2400/5020 (48%)]\tLoss: 1.061494\n",
      "Train Epoch: 7 [2440/5020 (49%)]\tLoss: 1.229947\n",
      "Train Epoch: 7 [2480/5020 (49%)]\tLoss: 1.021968\n",
      "Train Epoch: 7 [2520/5020 (50%)]\tLoss: 0.966909\n",
      "Train Epoch: 7 [2560/5020 (51%)]\tLoss: 1.032633\n",
      "Train Epoch: 7 [2600/5020 (52%)]\tLoss: 1.104671\n",
      "Train Epoch: 7 [2640/5020 (53%)]\tLoss: 0.856486\n",
      "Train Epoch: 7 [2680/5020 (53%)]\tLoss: 0.983963\n",
      "Train Epoch: 7 [2720/5020 (54%)]\tLoss: 0.980702\n",
      "Train Epoch: 7 [2760/5020 (55%)]\tLoss: 1.065877\n",
      "Train Epoch: 7 [2800/5020 (56%)]\tLoss: 0.954929\n",
      "Train Epoch: 7 [2840/5020 (57%)]\tLoss: 1.247176\n",
      "Train Epoch: 7 [2880/5020 (57%)]\tLoss: 1.099593\n",
      "Train Epoch: 7 [2920/5020 (58%)]\tLoss: 0.944357\n",
      "Train Epoch: 7 [2960/5020 (59%)]\tLoss: 1.115076\n",
      "Train Epoch: 7 [3000/5020 (60%)]\tLoss: 1.022061\n",
      "Train Epoch: 7 [3040/5020 (61%)]\tLoss: 1.137791\n",
      "Train Epoch: 7 [3080/5020 (61%)]\tLoss: 1.199890\n",
      "Train Epoch: 7 [3120/5020 (62%)]\tLoss: 1.220678\n",
      "Train Epoch: 7 [3160/5020 (63%)]\tLoss: 1.428080\n",
      "Train Epoch: 7 [3200/5020 (64%)]\tLoss: 0.887539\n",
      "Train Epoch: 7 [3240/5020 (65%)]\tLoss: 1.060261\n",
      "Train Epoch: 7 [3280/5020 (65%)]\tLoss: 0.752907\n",
      "Train Epoch: 7 [3320/5020 (66%)]\tLoss: 1.195930\n",
      "Train Epoch: 7 [3360/5020 (67%)]\tLoss: 1.008680\n",
      "Train Epoch: 7 [3400/5020 (68%)]\tLoss: 1.043495\n",
      "Train Epoch: 7 [3440/5020 (69%)]\tLoss: 0.814197\n",
      "Train Epoch: 7 [3480/5020 (69%)]\tLoss: 1.091936\n",
      "Train Epoch: 7 [3520/5020 (70%)]\tLoss: 1.211108\n",
      "Train Epoch: 7 [3560/5020 (71%)]\tLoss: 1.228828\n",
      "Train Epoch: 7 [3600/5020 (72%)]\tLoss: 1.269318\n",
      "Train Epoch: 7 [3640/5020 (73%)]\tLoss: 1.308957\n",
      "Train Epoch: 7 [3680/5020 (73%)]\tLoss: 1.006054\n",
      "Train Epoch: 7 [3720/5020 (74%)]\tLoss: 0.998504\n",
      "Train Epoch: 7 [3760/5020 (75%)]\tLoss: 1.053696\n",
      "Train Epoch: 7 [3800/5020 (76%)]\tLoss: 1.585794\n",
      "Train Epoch: 7 [3840/5020 (76%)]\tLoss: 1.083014\n",
      "Train Epoch: 7 [3880/5020 (77%)]\tLoss: 1.273033\n",
      "Train Epoch: 7 [3920/5020 (78%)]\tLoss: 0.954484\n",
      "Train Epoch: 7 [3960/5020 (79%)]\tLoss: 0.912562\n",
      "Train Epoch: 7 [4000/5020 (80%)]\tLoss: 1.140246\n",
      "Train Epoch: 7 [4040/5020 (80%)]\tLoss: 0.976929\n",
      "Train Epoch: 7 [4080/5020 (81%)]\tLoss: 0.930601\n",
      "Train Epoch: 7 [4120/5020 (82%)]\tLoss: 1.027843\n",
      "Train Epoch: 7 [4160/5020 (83%)]\tLoss: 1.128945\n",
      "Train Epoch: 7 [4200/5020 (84%)]\tLoss: 1.024964\n",
      "Train Epoch: 7 [4240/5020 (84%)]\tLoss: 0.930838\n",
      "Train Epoch: 7 [4280/5020 (85%)]\tLoss: 1.037640\n",
      "Train Epoch: 7 [4320/5020 (86%)]\tLoss: 1.030013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [4360/5020 (87%)]\tLoss: 1.148820\n",
      "Train Epoch: 7 [4400/5020 (88%)]\tLoss: 1.149477\n",
      "Train Epoch: 7 [4440/5020 (88%)]\tLoss: 1.433845\n",
      "Train Epoch: 7 [4480/5020 (89%)]\tLoss: 1.066870\n",
      "Train Epoch: 7 [4520/5020 (90%)]\tLoss: 0.959706\n",
      "Train Epoch: 7 [4560/5020 (91%)]\tLoss: 1.049703\n",
      "Train Epoch: 7 [4600/5020 (92%)]\tLoss: 0.943441\n",
      "Train Epoch: 7 [4640/5020 (92%)]\tLoss: 0.980943\n",
      "Train Epoch: 7 [4680/5020 (93%)]\tLoss: 0.942707\n",
      "Train Epoch: 7 [4720/5020 (94%)]\tLoss: 1.314946\n",
      "Train Epoch: 7 [4760/5020 (95%)]\tLoss: 1.233408\n",
      "Train Epoch: 7 [4800/5020 (96%)]\tLoss: 0.893873\n",
      "Train Epoch: 7 [4840/5020 (96%)]\tLoss: 0.896520\n",
      "Train Epoch: 7 [4880/5020 (97%)]\tLoss: 1.060878\n",
      "Train Epoch: 7 [4920/5020 (98%)]\tLoss: 1.165703\n",
      "Train Epoch: 7 [4960/5020 (99%)]\tLoss: 0.803354\n",
      "Train Epoch: 7 [5000/5020 (100%)]\tLoss: 1.239305\n",
      "\n",
      "Test set: Avg. loss: 1.0295, Accuracy: 247/519 (48%)\n",
      "\n",
      "Train Epoch: 8 [0/5020 (0%)]\tLoss: 1.631819\n",
      "Train Epoch: 8 [40/5020 (1%)]\tLoss: 0.988949\n",
      "Train Epoch: 8 [80/5020 (2%)]\tLoss: 1.009361\n",
      "Train Epoch: 8 [120/5020 (2%)]\tLoss: 1.371887\n",
      "Train Epoch: 8 [160/5020 (3%)]\tLoss: 0.824499\n",
      "Train Epoch: 8 [200/5020 (4%)]\tLoss: 0.774470\n",
      "Train Epoch: 8 [240/5020 (5%)]\tLoss: 1.368844\n",
      "Train Epoch: 8 [280/5020 (6%)]\tLoss: 1.117441\n",
      "Train Epoch: 8 [320/5020 (6%)]\tLoss: 0.850755\n",
      "Train Epoch: 8 [360/5020 (7%)]\tLoss: 0.869598\n",
      "Train Epoch: 8 [400/5020 (8%)]\tLoss: 1.008189\n",
      "Train Epoch: 8 [440/5020 (9%)]\tLoss: 0.981761\n",
      "Train Epoch: 8 [480/5020 (10%)]\tLoss: 1.079354\n",
      "Train Epoch: 8 [520/5020 (10%)]\tLoss: 0.883241\n",
      "Train Epoch: 8 [560/5020 (11%)]\tLoss: 0.822524\n",
      "Train Epoch: 8 [600/5020 (12%)]\tLoss: 1.136286\n",
      "Train Epoch: 8 [640/5020 (13%)]\tLoss: 0.954004\n",
      "Train Epoch: 8 [680/5020 (14%)]\tLoss: 0.930767\n",
      "Train Epoch: 8 [720/5020 (14%)]\tLoss: 1.088667\n",
      "Train Epoch: 8 [760/5020 (15%)]\tLoss: 1.308817\n",
      "Train Epoch: 8 [800/5020 (16%)]\tLoss: 1.118304\n",
      "Train Epoch: 8 [840/5020 (17%)]\tLoss: 1.073388\n",
      "Train Epoch: 8 [880/5020 (18%)]\tLoss: 1.188265\n",
      "Train Epoch: 8 [920/5020 (18%)]\tLoss: 1.555866\n",
      "Train Epoch: 8 [960/5020 (19%)]\tLoss: 0.931106\n",
      "Train Epoch: 8 [1000/5020 (20%)]\tLoss: 0.930053\n",
      "Train Epoch: 8 [1040/5020 (21%)]\tLoss: 1.058825\n",
      "Train Epoch: 8 [1080/5020 (22%)]\tLoss: 1.265527\n",
      "Train Epoch: 8 [1120/5020 (22%)]\tLoss: 0.962602\n",
      "Train Epoch: 8 [1160/5020 (23%)]\tLoss: 1.154131\n",
      "Train Epoch: 8 [1200/5020 (24%)]\tLoss: 0.947216\n",
      "Train Epoch: 8 [1240/5020 (25%)]\tLoss: 1.135635\n",
      "Train Epoch: 8 [1280/5020 (25%)]\tLoss: 0.931194\n",
      "Train Epoch: 8 [1320/5020 (26%)]\tLoss: 0.988703\n",
      "Train Epoch: 8 [1360/5020 (27%)]\tLoss: 0.802675\n",
      "Train Epoch: 8 [1400/5020 (28%)]\tLoss: 0.974624\n",
      "Train Epoch: 8 [1440/5020 (29%)]\tLoss: 0.895702\n",
      "Train Epoch: 8 [1480/5020 (29%)]\tLoss: 1.159011\n",
      "Train Epoch: 8 [1520/5020 (30%)]\tLoss: 1.461473\n",
      "Train Epoch: 8 [1560/5020 (31%)]\tLoss: 1.011850\n",
      "Train Epoch: 8 [1600/5020 (32%)]\tLoss: 0.919632\n",
      "Train Epoch: 8 [1640/5020 (33%)]\tLoss: 0.925954\n",
      "Train Epoch: 8 [1680/5020 (33%)]\tLoss: 1.253325\n",
      "Train Epoch: 8 [1720/5020 (34%)]\tLoss: 0.982751\n",
      "Train Epoch: 8 [1760/5020 (35%)]\tLoss: 1.057731\n",
      "Train Epoch: 8 [1800/5020 (36%)]\tLoss: 1.117153\n",
      "Train Epoch: 8 [1840/5020 (37%)]\tLoss: 1.034163\n",
      "Train Epoch: 8 [1880/5020 (37%)]\tLoss: 1.031870\n",
      "Train Epoch: 8 [1920/5020 (38%)]\tLoss: 1.002996\n",
      "Train Epoch: 8 [1960/5020 (39%)]\tLoss: 1.034676\n",
      "Train Epoch: 8 [2000/5020 (40%)]\tLoss: 1.230084\n",
      "Train Epoch: 8 [2040/5020 (41%)]\tLoss: 1.092763\n",
      "Train Epoch: 8 [2080/5020 (41%)]\tLoss: 1.204427\n",
      "Train Epoch: 8 [2120/5020 (42%)]\tLoss: 1.062078\n",
      "Train Epoch: 8 [2160/5020 (43%)]\tLoss: 1.008014\n",
      "Train Epoch: 8 [2200/5020 (44%)]\tLoss: 1.075961\n",
      "Train Epoch: 8 [2240/5020 (45%)]\tLoss: 1.235178\n",
      "Train Epoch: 8 [2280/5020 (45%)]\tLoss: 1.273137\n",
      "Train Epoch: 8 [2320/5020 (46%)]\tLoss: 0.832398\n",
      "Train Epoch: 8 [2360/5020 (47%)]\tLoss: 1.265376\n",
      "Train Epoch: 8 [2400/5020 (48%)]\tLoss: 1.120617\n",
      "Train Epoch: 8 [2440/5020 (49%)]\tLoss: 1.021219\n",
      "Train Epoch: 8 [2480/5020 (49%)]\tLoss: 1.189270\n",
      "Train Epoch: 8 [2520/5020 (50%)]\tLoss: 0.950294\n",
      "Train Epoch: 8 [2560/5020 (51%)]\tLoss: 1.110703\n",
      "Train Epoch: 8 [2600/5020 (52%)]\tLoss: 1.102722\n",
      "Train Epoch: 8 [2640/5020 (53%)]\tLoss: 1.002960\n",
      "Train Epoch: 8 [2680/5020 (53%)]\tLoss: 1.053368\n",
      "Train Epoch: 8 [2720/5020 (54%)]\tLoss: 1.074350\n",
      "Train Epoch: 8 [2760/5020 (55%)]\tLoss: 1.123674\n",
      "Train Epoch: 8 [2800/5020 (56%)]\tLoss: 1.109656\n",
      "Train Epoch: 8 [2840/5020 (57%)]\tLoss: 1.357769\n",
      "Train Epoch: 8 [2880/5020 (57%)]\tLoss: 1.190680\n",
      "Train Epoch: 8 [2920/5020 (58%)]\tLoss: 1.123597\n",
      "Train Epoch: 8 [2960/5020 (59%)]\tLoss: 1.001068\n",
      "Train Epoch: 8 [3000/5020 (60%)]\tLoss: 1.137842\n",
      "Train Epoch: 8 [3040/5020 (61%)]\tLoss: 1.017504\n",
      "Train Epoch: 8 [3080/5020 (61%)]\tLoss: 1.148790\n",
      "Train Epoch: 8 [3120/5020 (62%)]\tLoss: 0.977297\n",
      "Train Epoch: 8 [3160/5020 (63%)]\tLoss: 1.026857\n",
      "Train Epoch: 8 [3200/5020 (64%)]\tLoss: 0.936552\n",
      "Train Epoch: 8 [3240/5020 (65%)]\tLoss: 0.964649\n",
      "Train Epoch: 8 [3280/5020 (65%)]\tLoss: 1.177582\n",
      "Train Epoch: 8 [3320/5020 (66%)]\tLoss: 0.909225\n",
      "Train Epoch: 8 [3360/5020 (67%)]\tLoss: 1.251361\n",
      "Train Epoch: 8 [3400/5020 (68%)]\tLoss: 0.845858\n",
      "Train Epoch: 8 [3440/5020 (69%)]\tLoss: 0.954098\n",
      "Train Epoch: 8 [3480/5020 (69%)]\tLoss: 0.988223\n",
      "Train Epoch: 8 [3520/5020 (70%)]\tLoss: 0.822042\n",
      "Train Epoch: 8 [3560/5020 (71%)]\tLoss: 1.135323\n",
      "Train Epoch: 8 [3600/5020 (72%)]\tLoss: 0.764428\n",
      "Train Epoch: 8 [3640/5020 (73%)]\tLoss: 0.957505\n",
      "Train Epoch: 8 [3680/5020 (73%)]\tLoss: 0.846457\n",
      "Train Epoch: 8 [3720/5020 (74%)]\tLoss: 1.001032\n",
      "Train Epoch: 8 [3760/5020 (75%)]\tLoss: 0.825783\n",
      "Train Epoch: 8 [3800/5020 (76%)]\tLoss: 1.323908\n",
      "Train Epoch: 8 [3840/5020 (76%)]\tLoss: 0.986950\n",
      "Train Epoch: 8 [3880/5020 (77%)]\tLoss: 1.118399\n",
      "Train Epoch: 8 [3920/5020 (78%)]\tLoss: 2.432428\n",
      "Train Epoch: 8 [3960/5020 (79%)]\tLoss: 0.869243\n",
      "Train Epoch: 8 [4000/5020 (80%)]\tLoss: 0.942902\n",
      "Train Epoch: 8 [4040/5020 (80%)]\tLoss: 1.244987\n",
      "Train Epoch: 8 [4080/5020 (81%)]\tLoss: 1.123759\n",
      "Train Epoch: 8 [4120/5020 (82%)]\tLoss: 0.945153\n",
      "Train Epoch: 8 [4160/5020 (83%)]\tLoss: 1.099609\n",
      "Train Epoch: 8 [4200/5020 (84%)]\tLoss: 0.963370\n",
      "Train Epoch: 8 [4240/5020 (84%)]\tLoss: 0.854815\n",
      "Train Epoch: 8 [4280/5020 (85%)]\tLoss: 1.054295\n",
      "Train Epoch: 8 [4320/5020 (86%)]\tLoss: 0.913926\n",
      "Train Epoch: 8 [4360/5020 (87%)]\tLoss: 1.265802\n",
      "Train Epoch: 8 [4400/5020 (88%)]\tLoss: 1.006503\n",
      "Train Epoch: 8 [4440/5020 (88%)]\tLoss: 1.392546\n",
      "Train Epoch: 8 [4480/5020 (89%)]\tLoss: 0.724246\n",
      "Train Epoch: 8 [4520/5020 (90%)]\tLoss: 0.952896\n",
      "Train Epoch: 8 [4560/5020 (91%)]\tLoss: 0.991430\n",
      "Train Epoch: 8 [4600/5020 (92%)]\tLoss: 1.007199\n",
      "Train Epoch: 8 [4640/5020 (92%)]\tLoss: 0.951509\n",
      "Train Epoch: 8 [4680/5020 (93%)]\tLoss: 1.248158\n",
      "Train Epoch: 8 [4720/5020 (94%)]\tLoss: 0.957388\n",
      "Train Epoch: 8 [4760/5020 (95%)]\tLoss: 0.890166\n",
      "Train Epoch: 8 [4800/5020 (96%)]\tLoss: 1.663160\n",
      "Train Epoch: 8 [4840/5020 (96%)]\tLoss: 0.918083\n",
      "Train Epoch: 8 [4880/5020 (97%)]\tLoss: 1.075223\n",
      "Train Epoch: 8 [4920/5020 (98%)]\tLoss: 1.101898\n",
      "Train Epoch: 8 [4960/5020 (99%)]\tLoss: 1.133035\n",
      "Train Epoch: 8 [5000/5020 (100%)]\tLoss: 0.964540\n",
      "\n",
      "Test set: Avg. loss: 1.0280, Accuracy: 255/519 (49%)\n",
      "\n",
      "Train Epoch: 9 [0/5020 (0%)]\tLoss: 0.921204\n",
      "Train Epoch: 9 [40/5020 (1%)]\tLoss: 1.018763\n",
      "Train Epoch: 9 [80/5020 (2%)]\tLoss: 1.099038\n",
      "Train Epoch: 9 [120/5020 (2%)]\tLoss: 1.056299\n",
      "Train Epoch: 9 [160/5020 (3%)]\tLoss: 1.063954\n",
      "Train Epoch: 9 [200/5020 (4%)]\tLoss: 0.858709\n",
      "Train Epoch: 9 [240/5020 (5%)]\tLoss: 1.140639\n",
      "Train Epoch: 9 [280/5020 (6%)]\tLoss: 0.957865\n",
      "Train Epoch: 9 [320/5020 (6%)]\tLoss: 1.087125\n",
      "Train Epoch: 9 [360/5020 (7%)]\tLoss: 1.182457\n",
      "Train Epoch: 9 [400/5020 (8%)]\tLoss: 1.241888\n",
      "Train Epoch: 9 [440/5020 (9%)]\tLoss: 1.107455\n",
      "Train Epoch: 9 [480/5020 (10%)]\tLoss: 1.009933\n",
      "Train Epoch: 9 [520/5020 (10%)]\tLoss: 1.286866\n",
      "Train Epoch: 9 [560/5020 (11%)]\tLoss: 0.955251\n",
      "Train Epoch: 9 [600/5020 (12%)]\tLoss: 1.108512\n",
      "Train Epoch: 9 [640/5020 (13%)]\tLoss: 1.046439\n",
      "Train Epoch: 9 [680/5020 (14%)]\tLoss: 1.295020\n",
      "Train Epoch: 9 [720/5020 (14%)]\tLoss: 0.796127\n",
      "Train Epoch: 9 [760/5020 (15%)]\tLoss: 1.008492\n",
      "Train Epoch: 9 [800/5020 (16%)]\tLoss: 0.919122\n",
      "Train Epoch: 9 [840/5020 (17%)]\tLoss: 1.097587\n",
      "Train Epoch: 9 [880/5020 (18%)]\tLoss: 0.919096\n",
      "Train Epoch: 9 [920/5020 (18%)]\tLoss: 1.379310\n",
      "Train Epoch: 9 [960/5020 (19%)]\tLoss: 1.435343\n",
      "Train Epoch: 9 [1000/5020 (20%)]\tLoss: 0.993828\n",
      "Train Epoch: 9 [1040/5020 (21%)]\tLoss: 1.698712\n",
      "Train Epoch: 9 [1080/5020 (22%)]\tLoss: 0.937517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [1120/5020 (22%)]\tLoss: 1.077276\n",
      "Train Epoch: 9 [1160/5020 (23%)]\tLoss: 0.940240\n",
      "Train Epoch: 9 [1200/5020 (24%)]\tLoss: 1.215696\n",
      "Train Epoch: 9 [1240/5020 (25%)]\tLoss: 0.737921\n",
      "Train Epoch: 9 [1280/5020 (25%)]\tLoss: 1.059930\n",
      "Train Epoch: 9 [1320/5020 (26%)]\tLoss: 1.081724\n",
      "Train Epoch: 9 [1360/5020 (27%)]\tLoss: 0.952554\n",
      "Train Epoch: 9 [1400/5020 (28%)]\tLoss: 0.899455\n",
      "Train Epoch: 9 [1440/5020 (29%)]\tLoss: 0.959901\n",
      "Train Epoch: 9 [1480/5020 (29%)]\tLoss: 0.965587\n",
      "Train Epoch: 9 [1520/5020 (30%)]\tLoss: 0.927807\n",
      "Train Epoch: 9 [1560/5020 (31%)]\tLoss: 1.171038\n",
      "Train Epoch: 9 [1600/5020 (32%)]\tLoss: 0.934932\n",
      "Train Epoch: 9 [1640/5020 (33%)]\tLoss: 1.136378\n",
      "Train Epoch: 9 [1680/5020 (33%)]\tLoss: 1.090138\n",
      "Train Epoch: 9 [1720/5020 (34%)]\tLoss: 0.895982\n",
      "Train Epoch: 9 [1760/5020 (35%)]\tLoss: 1.264411\n",
      "Train Epoch: 9 [1800/5020 (36%)]\tLoss: 1.105759\n",
      "Train Epoch: 9 [1840/5020 (37%)]\tLoss: 1.035390\n",
      "Train Epoch: 9 [1880/5020 (37%)]\tLoss: 1.229943\n",
      "Train Epoch: 9 [1920/5020 (38%)]\tLoss: 1.105563\n",
      "Train Epoch: 9 [1960/5020 (39%)]\tLoss: 1.024808\n",
      "Train Epoch: 9 [2000/5020 (40%)]\tLoss: 1.105983\n",
      "Train Epoch: 9 [2040/5020 (41%)]\tLoss: 1.038667\n",
      "Train Epoch: 9 [2080/5020 (41%)]\tLoss: 1.034281\n",
      "Train Epoch: 9 [2120/5020 (42%)]\tLoss: 1.176985\n",
      "Train Epoch: 9 [2160/5020 (43%)]\tLoss: 0.985362\n",
      "Train Epoch: 9 [2200/5020 (44%)]\tLoss: 1.091228\n",
      "Train Epoch: 9 [2240/5020 (45%)]\tLoss: 0.947191\n",
      "Train Epoch: 9 [2280/5020 (45%)]\tLoss: 1.261117\n",
      "Train Epoch: 9 [2320/5020 (46%)]\tLoss: 1.020635\n",
      "Train Epoch: 9 [2360/5020 (47%)]\tLoss: 1.233643\n",
      "Train Epoch: 9 [2400/5020 (48%)]\tLoss: 0.988730\n",
      "Train Epoch: 9 [2440/5020 (49%)]\tLoss: 1.138653\n",
      "Train Epoch: 9 [2480/5020 (49%)]\tLoss: 0.973632\n",
      "Train Epoch: 9 [2520/5020 (50%)]\tLoss: 1.049797\n",
      "Train Epoch: 9 [2560/5020 (51%)]\tLoss: 1.018753\n",
      "Train Epoch: 9 [2600/5020 (52%)]\tLoss: 1.348149\n",
      "Train Epoch: 9 [2640/5020 (53%)]\tLoss: 1.030493\n",
      "Train Epoch: 9 [2680/5020 (53%)]\tLoss: 1.307337\n",
      "Train Epoch: 9 [2720/5020 (54%)]\tLoss: 0.894805\n",
      "Train Epoch: 9 [2760/5020 (55%)]\tLoss: 1.078833\n",
      "Train Epoch: 9 [2800/5020 (56%)]\tLoss: 0.803233\n",
      "Train Epoch: 9 [2840/5020 (57%)]\tLoss: 1.205053\n",
      "Train Epoch: 9 [2880/5020 (57%)]\tLoss: 0.863722\n",
      "Train Epoch: 9 [2920/5020 (58%)]\tLoss: 0.868048\n",
      "Train Epoch: 9 [2960/5020 (59%)]\tLoss: 0.777774\n",
      "Train Epoch: 9 [3000/5020 (60%)]\tLoss: 1.131432\n",
      "Train Epoch: 9 [3040/5020 (61%)]\tLoss: 1.460707\n",
      "Train Epoch: 9 [3080/5020 (61%)]\tLoss: 1.185629\n",
      "Train Epoch: 9 [3120/5020 (62%)]\tLoss: 0.855394\n",
      "Train Epoch: 9 [3160/5020 (63%)]\tLoss: 1.003478\n",
      "Train Epoch: 9 [3200/5020 (64%)]\tLoss: 0.933007\n",
      "Train Epoch: 9 [3240/5020 (65%)]\tLoss: 0.960863\n",
      "Train Epoch: 9 [3280/5020 (65%)]\tLoss: 1.181804\n",
      "Train Epoch: 9 [3320/5020 (66%)]\tLoss: 1.159675\n",
      "Train Epoch: 9 [3360/5020 (67%)]\tLoss: 1.092927\n",
      "Train Epoch: 9 [3400/5020 (68%)]\tLoss: 1.065966\n",
      "Train Epoch: 9 [3440/5020 (69%)]\tLoss: 0.822054\n",
      "Train Epoch: 9 [3480/5020 (69%)]\tLoss: 1.013005\n",
      "Train Epoch: 9 [3520/5020 (70%)]\tLoss: 0.914933\n",
      "Train Epoch: 9 [3560/5020 (71%)]\tLoss: 0.887352\n",
      "Train Epoch: 9 [3600/5020 (72%)]\tLoss: 1.276176\n",
      "Train Epoch: 9 [3640/5020 (73%)]\tLoss: 1.402995\n",
      "Train Epoch: 9 [3680/5020 (73%)]\tLoss: 1.106517\n",
      "Train Epoch: 9 [3720/5020 (74%)]\tLoss: 1.210841\n",
      "Train Epoch: 9 [3760/5020 (75%)]\tLoss: 1.185814\n",
      "Train Epoch: 9 [3800/5020 (76%)]\tLoss: 1.062996\n",
      "Train Epoch: 9 [3840/5020 (76%)]\tLoss: 1.268654\n",
      "Train Epoch: 9 [3880/5020 (77%)]\tLoss: 0.971228\n",
      "Train Epoch: 9 [3920/5020 (78%)]\tLoss: 1.100646\n",
      "Train Epoch: 9 [3960/5020 (79%)]\tLoss: 1.007930\n",
      "Train Epoch: 9 [4000/5020 (80%)]\tLoss: 0.990466\n",
      "Train Epoch: 9 [4040/5020 (80%)]\tLoss: 1.095601\n",
      "Train Epoch: 9 [4080/5020 (81%)]\tLoss: 1.356140\n",
      "Train Epoch: 9 [4120/5020 (82%)]\tLoss: 0.983615\n",
      "Train Epoch: 9 [4160/5020 (83%)]\tLoss: 1.294988\n",
      "Train Epoch: 9 [4200/5020 (84%)]\tLoss: 1.107642\n",
      "Train Epoch: 9 [4240/5020 (84%)]\tLoss: 0.876580\n",
      "Train Epoch: 9 [4280/5020 (85%)]\tLoss: 1.011424\n",
      "Train Epoch: 9 [4320/5020 (86%)]\tLoss: 1.243348\n",
      "Train Epoch: 9 [4360/5020 (87%)]\tLoss: 0.999566\n",
      "Train Epoch: 9 [4400/5020 (88%)]\tLoss: 1.020835\n",
      "Train Epoch: 9 [4440/5020 (88%)]\tLoss: 1.176241\n",
      "Train Epoch: 9 [4480/5020 (89%)]\tLoss: 1.261997\n",
      "Train Epoch: 9 [4520/5020 (90%)]\tLoss: 0.942681\n",
      "Train Epoch: 9 [4560/5020 (91%)]\tLoss: 1.152581\n",
      "Train Epoch: 9 [4600/5020 (92%)]\tLoss: 0.976730\n",
      "Train Epoch: 9 [4640/5020 (92%)]\tLoss: 1.164491\n",
      "Train Epoch: 9 [4680/5020 (93%)]\tLoss: 1.450483\n",
      "Train Epoch: 9 [4720/5020 (94%)]\tLoss: 1.204291\n",
      "Train Epoch: 9 [4760/5020 (95%)]\tLoss: 0.913292\n",
      "Train Epoch: 9 [4800/5020 (96%)]\tLoss: 1.053491\n",
      "Train Epoch: 9 [4840/5020 (96%)]\tLoss: 1.243654\n",
      "Train Epoch: 9 [4880/5020 (97%)]\tLoss: 0.915681\n",
      "Train Epoch: 9 [4920/5020 (98%)]\tLoss: 0.961094\n",
      "Train Epoch: 9 [4960/5020 (99%)]\tLoss: 1.067781\n",
      "Train Epoch: 9 [5000/5020 (100%)]\tLoss: 1.149836\n",
      "\n",
      "Test set: Avg. loss: 1.0197, Accuracy: 253/519 (49%)\n",
      "\n",
      "Train Epoch: 10 [0/5020 (0%)]\tLoss: 0.991994\n",
      "Train Epoch: 10 [40/5020 (1%)]\tLoss: 0.936282\n",
      "Train Epoch: 10 [80/5020 (2%)]\tLoss: 1.013267\n",
      "Train Epoch: 10 [120/5020 (2%)]\tLoss: 1.127442\n",
      "Train Epoch: 10 [160/5020 (3%)]\tLoss: 1.015168\n",
      "Train Epoch: 10 [200/5020 (4%)]\tLoss: 0.781236\n",
      "Train Epoch: 10 [240/5020 (5%)]\tLoss: 0.883814\n",
      "Train Epoch: 10 [280/5020 (6%)]\tLoss: 1.043593\n",
      "Train Epoch: 10 [320/5020 (6%)]\tLoss: 1.005786\n",
      "Train Epoch: 10 [360/5020 (7%)]\tLoss: 0.873144\n",
      "Train Epoch: 10 [400/5020 (8%)]\tLoss: 0.962156\n",
      "Train Epoch: 10 [440/5020 (9%)]\tLoss: 0.873109\n",
      "Train Epoch: 10 [480/5020 (10%)]\tLoss: 1.175113\n",
      "Train Epoch: 10 [520/5020 (10%)]\tLoss: 0.959856\n",
      "Train Epoch: 10 [560/5020 (11%)]\tLoss: 1.054971\n",
      "Train Epoch: 10 [600/5020 (12%)]\tLoss: 0.856202\n",
      "Train Epoch: 10 [640/5020 (13%)]\tLoss: 0.744754\n",
      "Train Epoch: 10 [680/5020 (14%)]\tLoss: 1.076409\n",
      "Train Epoch: 10 [720/5020 (14%)]\tLoss: 0.995986\n",
      "Train Epoch: 10 [760/5020 (15%)]\tLoss: 1.025334\n",
      "Train Epoch: 10 [800/5020 (16%)]\tLoss: 1.098302\n",
      "Train Epoch: 10 [840/5020 (17%)]\tLoss: 1.137945\n",
      "Train Epoch: 10 [880/5020 (18%)]\tLoss: 0.983071\n",
      "Train Epoch: 10 [920/5020 (18%)]\tLoss: 1.146313\n",
      "Train Epoch: 10 [960/5020 (19%)]\tLoss: 1.075324\n",
      "Train Epoch: 10 [1000/5020 (20%)]\tLoss: 0.891393\n",
      "Train Epoch: 10 [1040/5020 (21%)]\tLoss: 0.977746\n",
      "Train Epoch: 10 [1080/5020 (22%)]\tLoss: 0.723084\n",
      "Train Epoch: 10 [1120/5020 (22%)]\tLoss: 1.215795\n",
      "Train Epoch: 10 [1160/5020 (23%)]\tLoss: 0.998041\n",
      "Train Epoch: 10 [1200/5020 (24%)]\tLoss: 1.028330\n",
      "Train Epoch: 10 [1240/5020 (25%)]\tLoss: 0.937585\n",
      "Train Epoch: 10 [1280/5020 (25%)]\tLoss: 0.905482\n",
      "Train Epoch: 10 [1320/5020 (26%)]\tLoss: 1.279954\n",
      "Train Epoch: 10 [1360/5020 (27%)]\tLoss: 0.963245\n",
      "Train Epoch: 10 [1400/5020 (28%)]\tLoss: 1.025700\n",
      "Train Epoch: 10 [1440/5020 (29%)]\tLoss: 0.687094\n",
      "Train Epoch: 10 [1480/5020 (29%)]\tLoss: 1.126481\n",
      "Train Epoch: 10 [1520/5020 (30%)]\tLoss: 0.933385\n",
      "Train Epoch: 10 [1560/5020 (31%)]\tLoss: 1.381354\n",
      "Train Epoch: 10 [1600/5020 (32%)]\tLoss: 0.902232\n",
      "Train Epoch: 10 [1640/5020 (33%)]\tLoss: 0.827878\n",
      "Train Epoch: 10 [1680/5020 (33%)]\tLoss: 0.968020\n",
      "Train Epoch: 10 [1720/5020 (34%)]\tLoss: 1.293995\n",
      "Train Epoch: 10 [1760/5020 (35%)]\tLoss: 0.944885\n",
      "Train Epoch: 10 [1800/5020 (36%)]\tLoss: 0.930671\n",
      "Train Epoch: 10 [1840/5020 (37%)]\tLoss: 1.572448\n",
      "Train Epoch: 10 [1880/5020 (37%)]\tLoss: 1.507311\n",
      "Train Epoch: 10 [1920/5020 (38%)]\tLoss: 0.728051\n",
      "Train Epoch: 10 [1960/5020 (39%)]\tLoss: 0.949198\n",
      "Train Epoch: 10 [2000/5020 (40%)]\tLoss: 0.917445\n",
      "Train Epoch: 10 [2040/5020 (41%)]\tLoss: 1.146400\n",
      "Train Epoch: 10 [2080/5020 (41%)]\tLoss: 0.902555\n",
      "Train Epoch: 10 [2120/5020 (42%)]\tLoss: 1.118289\n",
      "Train Epoch: 10 [2160/5020 (43%)]\tLoss: 1.306663\n",
      "Train Epoch: 10 [2200/5020 (44%)]\tLoss: 0.842142\n",
      "Train Epoch: 10 [2240/5020 (45%)]\tLoss: 1.103514\n",
      "Train Epoch: 10 [2280/5020 (45%)]\tLoss: 0.982488\n",
      "Train Epoch: 10 [2320/5020 (46%)]\tLoss: 0.789736\n",
      "Train Epoch: 10 [2360/5020 (47%)]\tLoss: 0.760550\n",
      "Train Epoch: 10 [2400/5020 (48%)]\tLoss: 1.009424\n",
      "Train Epoch: 10 [2440/5020 (49%)]\tLoss: 1.114090\n",
      "Train Epoch: 10 [2480/5020 (49%)]\tLoss: 1.122624\n",
      "Train Epoch: 10 [2520/5020 (50%)]\tLoss: 1.178109\n",
      "Train Epoch: 10 [2560/5020 (51%)]\tLoss: 0.649995\n",
      "Train Epoch: 10 [2600/5020 (52%)]\tLoss: 1.232613\n",
      "Train Epoch: 10 [2640/5020 (53%)]\tLoss: 0.902328\n",
      "Train Epoch: 10 [2680/5020 (53%)]\tLoss: 0.854104\n",
      "Train Epoch: 10 [2720/5020 (54%)]\tLoss: 0.822767\n",
      "Train Epoch: 10 [2760/5020 (55%)]\tLoss: 1.383077\n",
      "Train Epoch: 10 [2800/5020 (56%)]\tLoss: 1.036380\n",
      "Train Epoch: 10 [2840/5020 (57%)]\tLoss: 0.977799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [2880/5020 (57%)]\tLoss: 0.909784\n",
      "Train Epoch: 10 [2920/5020 (58%)]\tLoss: 1.085249\n",
      "Train Epoch: 10 [2960/5020 (59%)]\tLoss: 0.833710\n",
      "Train Epoch: 10 [3000/5020 (60%)]\tLoss: 1.032132\n",
      "Train Epoch: 10 [3040/5020 (61%)]\tLoss: 1.064322\n",
      "Train Epoch: 10 [3080/5020 (61%)]\tLoss: 0.827934\n",
      "Train Epoch: 10 [3120/5020 (62%)]\tLoss: 1.363022\n",
      "Train Epoch: 10 [3160/5020 (63%)]\tLoss: 1.155865\n",
      "Train Epoch: 10 [3200/5020 (64%)]\tLoss: 0.911495\n",
      "Train Epoch: 10 [3240/5020 (65%)]\tLoss: 0.947805\n",
      "Train Epoch: 10 [3280/5020 (65%)]\tLoss: 0.825354\n",
      "Train Epoch: 10 [3320/5020 (66%)]\tLoss: 0.901036\n",
      "Train Epoch: 10 [3360/5020 (67%)]\tLoss: 0.873560\n",
      "Train Epoch: 10 [3400/5020 (68%)]\tLoss: 1.046563\n",
      "Train Epoch: 10 [3440/5020 (69%)]\tLoss: 1.008747\n",
      "Train Epoch: 10 [3480/5020 (69%)]\tLoss: 0.917340\n",
      "Train Epoch: 10 [3520/5020 (70%)]\tLoss: 0.981159\n",
      "Train Epoch: 10 [3560/5020 (71%)]\tLoss: 0.813661\n",
      "Train Epoch: 10 [3600/5020 (72%)]\tLoss: 1.278916\n",
      "Train Epoch: 10 [3640/5020 (73%)]\tLoss: 1.020098\n",
      "Train Epoch: 10 [3680/5020 (73%)]\tLoss: 1.251073\n",
      "Train Epoch: 10 [3720/5020 (74%)]\tLoss: 0.930173\n",
      "Train Epoch: 10 [3760/5020 (75%)]\tLoss: 1.036854\n",
      "Train Epoch: 10 [3800/5020 (76%)]\tLoss: 1.217847\n",
      "Train Epoch: 10 [3840/5020 (76%)]\tLoss: 1.192627\n",
      "Train Epoch: 10 [3880/5020 (77%)]\tLoss: 0.778292\n",
      "Train Epoch: 10 [3920/5020 (78%)]\tLoss: 1.654186\n",
      "Train Epoch: 10 [3960/5020 (79%)]\tLoss: 1.298958\n",
      "Train Epoch: 10 [4000/5020 (80%)]\tLoss: 1.001026\n",
      "Train Epoch: 10 [4040/5020 (80%)]\tLoss: 1.217338\n",
      "Train Epoch: 10 [4080/5020 (81%)]\tLoss: 0.987455\n",
      "Train Epoch: 10 [4120/5020 (82%)]\tLoss: 0.964615\n",
      "Train Epoch: 10 [4160/5020 (83%)]\tLoss: 0.992631\n",
      "Train Epoch: 10 [4200/5020 (84%)]\tLoss: 1.179840\n",
      "Train Epoch: 10 [4240/5020 (84%)]\tLoss: 0.873730\n",
      "Train Epoch: 10 [4280/5020 (85%)]\tLoss: 0.953309\n",
      "Train Epoch: 10 [4320/5020 (86%)]\tLoss: 0.938277\n",
      "Train Epoch: 10 [4360/5020 (87%)]\tLoss: 0.936473\n",
      "Train Epoch: 10 [4400/5020 (88%)]\tLoss: 0.854584\n",
      "Train Epoch: 10 [4440/5020 (88%)]\tLoss: 0.829831\n",
      "Train Epoch: 10 [4480/5020 (89%)]\tLoss: 1.139825\n",
      "Train Epoch: 10 [4520/5020 (90%)]\tLoss: 1.373882\n",
      "Train Epoch: 10 [4560/5020 (91%)]\tLoss: 1.388450\n",
      "Train Epoch: 10 [4600/5020 (92%)]\tLoss: 0.885378\n",
      "Train Epoch: 10 [4640/5020 (92%)]\tLoss: 1.110690\n",
      "Train Epoch: 10 [4680/5020 (93%)]\tLoss: 0.930964\n",
      "Train Epoch: 10 [4720/5020 (94%)]\tLoss: 1.011618\n",
      "Train Epoch: 10 [4760/5020 (95%)]\tLoss: 1.129197\n",
      "Train Epoch: 10 [4800/5020 (96%)]\tLoss: 0.899244\n",
      "Train Epoch: 10 [4840/5020 (96%)]\tLoss: 1.247762\n",
      "Train Epoch: 10 [4880/5020 (97%)]\tLoss: 0.980892\n",
      "Train Epoch: 10 [4920/5020 (98%)]\tLoss: 1.121443\n",
      "Train Epoch: 10 [4960/5020 (99%)]\tLoss: 1.147373\n",
      "Train Epoch: 10 [5000/5020 (100%)]\tLoss: 1.090673\n",
      "\n",
      "Test set: Avg. loss: 1.0269, Accuracy: 254/519 (49%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
